{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f90be53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       odometer_value  year_produced  price_usd  body_type_ordinal  automatic  \\\n",
      "37935          320000           2003     5200.0                0.0        0.0   \n",
      "28568          400000           1995     1700.0                0.0        1.0   \n",
      "24311           79000           2013    14500.0                1.0        0.0   \n",
      "19393          500000           2002     6500.0                1.0        1.0   \n",
      "2540           280000           2005     5000.0                0.0        0.0   \n",
      "...               ...            ...        ...                ...        ...   \n",
      "6265           300000           1998      820.0                3.0        0.0   \n",
      "11284          159000           2006     7300.0                5.0        0.0   \n",
      "38158           72420           2006    15300.0               11.0        1.0   \n",
      "860             77921           2014    14900.0                1.0        1.0   \n",
      "15795          355000           2004    10400.0                6.0        0.0   \n",
      "\n",
      "       mechanical  black  blue  brown  green  grey  orange  other  red  \\\n",
      "37935         1.0    0.0   0.0    0.0    0.0   0.0     0.0    0.0  0.0   \n",
      "28568         0.0    0.0   0.0    0.0    0.0   0.0     0.0    0.0  0.0   \n",
      "24311         1.0    0.0   0.0    0.0    0.0   1.0     0.0    0.0  0.0   \n",
      "19393         0.0    0.0   0.0    0.0    0.0   0.0     0.0    1.0  0.0   \n",
      "2540          1.0    0.0   0.0    0.0    0.0   0.0     0.0    0.0  0.0   \n",
      "...           ...    ...   ...    ...    ...   ...     ...    ...  ...   \n",
      "6265          1.0    0.0   0.0    0.0    0.0   0.0     0.0    0.0  0.0   \n",
      "11284         1.0    0.0   0.0    0.0    0.0   1.0     0.0    0.0  0.0   \n",
      "38158         0.0    0.0   0.0    0.0    0.0   0.0     0.0    0.0  0.0   \n",
      "860           0.0    0.0   0.0    0.0    0.0   0.0     1.0    0.0  0.0   \n",
      "15795         1.0    0.0   0.0    0.0    0.0   0.0     0.0    0.0  0.0   \n",
      "\n",
      "       silver  violet  white  yellow  \n",
      "37935     1.0     0.0    0.0     0.0  \n",
      "28568     0.0     1.0    0.0     0.0  \n",
      "24311     0.0     0.0    0.0     0.0  \n",
      "19393     0.0     0.0    0.0     0.0  \n",
      "2540      1.0     0.0    0.0     0.0  \n",
      "...       ...     ...    ...     ...  \n",
      "6265      1.0     0.0    0.0     0.0  \n",
      "11284     0.0     0.0    0.0     0.0  \n",
      "38158     0.0     0.0    1.0     0.0  \n",
      "860       0.0     0.0    0.0     0.0  \n",
      "15795     0.0     0.0    1.0     0.0  \n",
      "\n",
      "[30824 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing the dataset into a pandas dataframe\n",
    "df = pd.read_csv(\"cars.csv\")\n",
    "\n",
    "# note your selected features to address the concern.  Select \"useful\" columns.  You do not need many.\n",
    "useful_columns = ['price_usd', 'odometer_value', 'year_produced', 'transmission', 'body_type', 'color', 'duration_listed']\n",
    "\n",
    "#Remove Unwanted Columns\n",
    "columns_to_drop = [col for col in df.columns if col not in useful_columns]\n",
    "df.drop(columns = columns_to_drop, inplace=True)\n",
    "\n",
    "# Seperate X and y (features and label)  The last feature \"duration_listed\" is the label (y)\n",
    "# Seperate X vs Y\n",
    "X = df.drop('duration_listed', axis=1)\n",
    "y = df['duration_listed']\n",
    "\n",
    "# Do the ordinal Encoder for car type to reflect that some cars are bigger than others.  \n",
    "# This is the order 'universal','hatchback', 'cabriolet','coupe','sedan','liftback', 'suv', 'minivan', 'van','pickup', 'minibus','limousine'\n",
    "# make sure this is the entire set by using unique()\n",
    "# create a seperate dataframe for the ordinal number - so you must strip it out and save the column\n",
    "# make sure to save the OrdinalEncoder for future encoding due to inference\n",
    "\n",
    "body_type = df['body_type'].unique()\n",
    "ordinal_encoder = OrdinalEncoder(categories=[body_type])\n",
    "df['body_type_ordinal'] = ordinal_encoder.fit_transform(df[['body_type']])\n",
    "df_ordinal = pd.DataFrame(df['body_type_ordinal'], columns=['body_type_ordinal'])\n",
    "category_mapping_df = pd.DataFrame({\n",
    "    'body_type': body_type,\n",
    "    'encoded_value': range(len(body_type))\n",
    "})\n",
    "\n",
    "category_mapping_df.to_csv('body_type_ordinal_mapping.csv', index=False)\n",
    "df.drop(\"body_type_ordinal\",  axis='columns', inplace=True)\n",
    "\n",
    "# Do onehotencoder the selected features - again you need to make a new dataframe with just the encoding of the transmission\n",
    "# save the OneHotEncoder to use for future encoding of transmission due to inference\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "transmission_encoded = onehot_encoder.fit_transform(df[['transmission']])\n",
    "transmission_categories = onehot_encoder.categories_[0]\n",
    "transmission_encoded_df = pd.DataFrame(transmission_encoded, columns=transmission_categories)\n",
    "pd.DataFrame(transmission_categories, columns=['transmission_type']).to_csv('transmission_types.csv', index=False)\n",
    "\n",
    "# Do onehotencoder for Color\n",
    "# Save the OneHotEncoder to use for future encoding of color for inference\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "color_encoded = onehot_encoder.fit_transform(df[['color']])\n",
    "color_categories = onehot_encoder.categories_[0]\n",
    "color_encoded_df = pd.DataFrame(color_encoded, columns=color_categories)\n",
    "pd.DataFrame(color_categories, columns=['color_type']).to_csv('color_types.csv', index=False)\n",
    "\n",
    "# combine all three together endocdings into 1 data frame (need 2 steps with \"concatenate\")\n",
    "# add the ordinal and transmission then add color\n",
    "\n",
    "encoded_df = pd.concat([df_ordinal, transmission_encoded_df, color_encoded_df], axis=1)\n",
    "\n",
    "# then dd to original data set\n",
    "\n",
    "df_final = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "#delete the columns that are substituted by ordinal and onehot - delete the text columns for color, transmission, and car type \n",
    "\n",
    "df_final.drop(['body_type', 'transmission', 'color'], axis=1, inplace=True)\n",
    "\n",
    "X = df_final.drop('duration_listed', axis=1)\n",
    "y = df_final['duration_listed']\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)        \n",
    "\n",
    "# Feature Scaling - required due to different orders of magnitude across the features\n",
    "# make sure to save the scaler for future use in inference\n",
    "scaler = StandardScaler()\n",
    "print(X_train)\n",
    "#         X_train_scaled = scaler.fit_transform(X_train)\n",
    "#         X_test_scaled = scaler.transform(X_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c71efc15",
   "metadata": {},
   "outputs": [],
   "source": [
    " # this demonstrates how you have to convert these values using the encoders and scalers above (if you choose these columns - you are free to choose any you like)\n",
    "def model_infer(transmission, color, odometer, year, bodytype, price):\n",
    "\n",
    "    #convert the body type into a numpy array that holds the correct encoding\n",
    "    mapping_df = pd.read_csv('body_type_ordinal_mapping.csv')\n",
    "    body_type_mapping = pd.Series(mapping_df.encoded_value.values, index=mapping_df.body_type).to_dict()\n",
    "    carTypeTest = np.array([[body_type_mapping[bodytype]]])\n",
    "\n",
    "    print(carTypeTest)\n",
    "    \n",
    "    #convert the transmission into a numpy array with the correct encoding\n",
    "    mapping_df = pd.read_csv('transmission_types.csv')\n",
    "    transmission_type_mapping = pd.Series(mapping_df.index, index=mapping_df.transmission_type).to_dict()\n",
    "    one_hot_transmission = np.zeros((1, len(transmission_type_mapping)))\n",
    "    transmission_index = transmission_type_mapping[transmission]\n",
    "    one_hot_transmission[0, transmission_index] = 1\n",
    "    carHotTransmissionTest = one_hot_transmission\n",
    "\n",
    "    print(carHotTransmissionTest)\n",
    "\n",
    "    #conver the color into a numpy array with the correct encoding\n",
    "    mapping_df = pd.read_csv('color_types.csv')\n",
    "    color_type_mapping = pd.Series(mapping_df.index, index=mapping_df.color_type).to_dict()\n",
    "    one_hot_color = np.zeros((1, len(color_type_mapping)))\n",
    "    color_index = color_type_mapping[color]\n",
    "    one_hot_color[0, color_index] = 1\n",
    "    carHotColorTest = one_hot_color\n",
    "\n",
    "    print(carHotColorTest)\n",
    "    \n",
    "    #add the three above\n",
    "    total = np.concatenate((carTypeTest,carHotTransmissionTest), 1)\n",
    "    total = np.concatenate((total,carHotColorTest), 1)\n",
    "\n",
    "    # build a complete test array and then predict\n",
    "    othercolumns = np.array([[odometer ,year, price]])\n",
    "    totaltotal = np.concatenate((total, othercolumns),1)\n",
    "\n",
    "    #must scale\n",
    "    scaler = StandardScaler()\n",
    "    attempt = scaler.transform(totaltotal)\n",
    "\n",
    "    #determine prediction\n",
    "    y_pred = self.model.predict(attempt)\n",
    "    return str(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "894c3a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]]\n",
      "[[0. 1.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_841/1684433415.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransmission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0modometer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbodytype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_841/782046228.py\u001b[0m in \u001b[0;36mmodel_infer\u001b[0;34m(transmission, color, odometer, year, bodytype, price)\u001b[0m\n\u001b[1;32m     39\u001b[0m    \u001b[0;31m#must scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m    \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m    \u001b[0mattempt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotaltotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m    \u001b[0;31m#determine prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \"\"\"\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "transmission = 'mechanical'\n",
    "color = 'red'\n",
    "odometer = 50000\n",
    "year = 2015\n",
    "bodytype = 'sedan'\n",
    "price = 15000\n",
    "\n",
    "model_infer(transmission, color, odometer, year, bodytype, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac9bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
