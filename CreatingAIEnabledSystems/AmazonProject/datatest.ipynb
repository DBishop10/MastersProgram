{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from data_pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1160/4261714582.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'amazon_movie_reviews.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1702\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \"\"\"\n\u001b[1;32m   1337\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('amazon_movie_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = df['text'].iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(corpus):\n",
    "    tokens = corpus.str.lower().str.split().explode().reset_index(name='token')\n",
    "\n",
    "    vocab = {word: idx for idx, word in enumerate(tokens['token'].unique())}\n",
    "\n",
    "    tokens['token_index'] = tokens['token'].map(vocab)\n",
    "    \n",
    "    preprocessed_corpus = tokens.groupby('index')['token_index'].agg(list)\n",
    "\n",
    "    return vocab, preprocessed_corpus\n",
    "\n",
    "def encode(tokens, method='bow'):\n",
    "    if isinstance(tokens.iloc[0], list):  # Check if the first element is a list (indicative of token indices)\n",
    "        str_corpus = tokens.apply(lambda x: ' '.join(map(str, x)))\n",
    "    else:\n",
    "        str_corpus = tokens\n",
    "\n",
    "    if method == 'bow':\n",
    "        # Bag of Words Encoding\n",
    "        vectorizer = CountVectorizer()\n",
    "        encoded_data = vectorizer.fit_transform(str_corpus)\n",
    "        return encoded_data, vectorizer.get_feature_names_out()\n",
    "\n",
    "    elif method == 'tfidf':\n",
    "        # TF-IDF Encoding\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        encoded_data = vectorizer.fit_transform(str_corpus)\n",
    "        return encoded_data, vectorizer.get_feature_names_out()\n",
    "\n",
    "    elif method == 'word2vec':\n",
    "        #word2vec encoding model\n",
    "        tokenized_docs = [word_tokenize(doc.lower()) for doc in str_corpus]\n",
    "        word2vec_model = Word2Vec(tokenized_docs, vector_size=100, window=5, min_count=2, workers=4, epochs=10)\n",
    "        return word2vec_model\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported encoding method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amazon,': 0, 'please': 1, 'buy': 2, 'the': 3, 'show!': 4, \"i'm\": 5, 'hooked!': 6, 'my': 7, 'kiddos': 8, 'love': 9, 'this': 10, 'show!!': 11, 'annabella': 12, 'sciorra': 13, 'did': 14, 'her': 15, 'character': 16, 'justice': 17, 'with': 18, 'portrayal': 19, 'of': 20, 'a': 21, 'mentally': 22, 'ill,': 23, 'depressed': 24, 'and': 25, 'traumatized': 26, 'individual': 27, 'who': 28, 'projects': 29, 'much': 30, 'inner': 31, 'wounds': 32, 'onto': 33, 'others.': 34, 'challenges': 35, 'she': 36, 'faces': 37, 'father': 38, 'were': 39, 'sensitively': 40, 'portrayed': 41, 'resonate': 42, 'understanding': 43, 'love.': 44, 'ending': 45, 'really': 46, \"isn't\": 47, 'an': 48, 'ending,': 49, 'though': 50, 'feels': 51, 'like': 52, 'it': 53, 'was': 54, 'abandoned': 55, 'not': 56, 'enough': 57, 'closure': 58, 'but': 59, 'other': 60, 'than': 61, 'that,': 62, 'its': 63, 'decent': 64, 'movie': 65, 'to': 66, 'sit': 67, 'through': 68, 'if': 69, \"you're\": 70, 'type': 71, 'person': 72, 'likes': 73, 'people-watch': 74, 'or': 75, 'analyze': 76, 'actions': 77, 'has': 78, 'independent-movie': 79, 'feel': 80, 'which': 81, 'is': 82, 'also': 83, 'somewhat': 84, 'comforting.': 85, '...there': 86, 'should': 87, 'be': 88, 'more': 89, 'range': 90, 'characters': 91, 'high-functioning': 92, 'autism,': 93, 'too.': 94, 'jack': 95, 'closest': 96, 'representation': 97, 'falls': 98, 'on': 99, 'severe': 100, 'scale,': 101, 'socially.': 102, 'i': 103, 'that': 104, 'storyline': 105, 'some': 106, 'episodes': 107, 'tie': 108, 'in': 109, 'heartwarming,': 110, 'moving': 111, 'moments': 112, 'depict': 113, 'struggles': 114, 'often': 115, 'faced': 116, 'by': 117, 'those': 118, 'spectrum.': 119, 'show': 120, 'definitely': 121, 'ton': 122, 'potential': 123, 'hope': 124, 'future': 125, 'seasons': 126, 'bring': 127, 'diverse': 128, 'complex': 129, \"...isn't\": 130, 'always': 131, 'how': 132, 'you': 133, 'expect': 134, 'be,': 135, 'when': 136, 'there,': 137, 'know.': 138, 'what': 139, 'all': 140, 'about.': 141, 'deep': 142, 'within': 143, 'broken': 144, 'home': 145, 'mother': 146, 'addiction': 147, 'best': 148, 'friend': 149, 'whom': 150, 'nobody': 151, 'else': 152, 'seems': 153, 'understand': 154, 'him.': 155, \"there's\": 156, 'loss,': 157, 'triumph.': 158, 'bit': 159, 'magic': 160, 'psychic': 161, 'neighbor': 162, 'makes': 163, 'quite': 164, 'impact': 165, 'boy.': 166, 'one': 167, 'worth': 168, 'your': 169, 'time.': 170, 'as': 171, 'learn': 172, 'about': 173, 'very': 174, 'unique': 175, 'values': 176, 'they': 177, 'hold': 178, 'dear,': 179, 'notice': 180, 'sweet': 181, 'simple': 182, 'things': 183, 'them': 184, 'will': 185, 'make': 186, 'smile.': 187, 'then': 188, 'moves': 189, 'deeper,': 190, 'poetic': 191, 'script': 192, 'pulls': 193, 'even': 194, 'reminding': 195, 'memories': 196, 'might': 197, 'have': 198, 'forgotten': 199, 'movies': 200, 'do.': 201, 'words': 202, 'inspires': 203, 'emotions': 204, 'just': 205, 'motivate': 206, 'do': 207, 'thing': 208, \"you've\": 209, 'been': 210, 'procrastinating': 211, 'for': 212, 'too': 213, 'long.': 214, 'visual': 215, 'play': 216, 'light': 217, 'color': 218, 'throughout': 219, 'film': 220, 'complements': 221, 'depth.': 222, 'must-see!!!': 223, 'our': 224, 'family': 225, 'loved': 226, 'film.': 227, 'we': 228, 'kids': 229, 'thought': 230, 'so': 231, 'fun.': 232, 'liked': 233, 'reviews': 234, 'harsh.': 235, 'honestly': 236, 'don‚Äôt': 237, 'think': 238, 'previews': 239, 'great.': 240, 'it‚Äôs': 241, 'watching.': 242, 'great': 243, 'around.': 244, 'films': 245, 'jesus': 246, 'can': 247, 'rough.': 248, 'legit.': 249, 'movie!': 250, 'are': 251, 'obsessed': 252, 'hp!': 253, 'hits': 254, 'feels!': 255, 'amazing': 256, 'story': 257, '&': 258, 'documentary!': 259, 'woodlawn': 260, 'behind': 261, 'it!': 262, 'exciting': 263, 'super': 264, 'funny!': 265, 'both': 266, 'jennifer': 267, 'jason': 268, 'fabulous!': 269, 'dvd': 270, 'great!': 271, 'am': 272, 'stay': 273, 'at': 274, 'mom': 275, 'totally': 276, 'out': 277, 'shape.': 278, \"don't\": 279, 'alot': 280, 'time': 281, 'myself': 282, 'workout': 283, 'fits': 284, 'bill.': 285, '5': 286, 'different': 287, '10': 288, 'minute': 289, 'workouts': 290, 'each': 291, 'individually': 292, '2,': 293, '3,': 294, '4': 295, 'menu': 296, 'gives': 297, 'option': 298, 'personalizing': 299, 'little': 300, 'many': 301, 'workouts.': 302, 'plus': 303, 'targets': 304, 'areas': 305, 'body.': 306, \"doesn't\": 307, 'get': 308, 'any': 309, 'easier': 310, 'this.': 311, 'never': 312, 'done': 313, 'pilates': 314, 'before': 315, 'beginner': 316, 'workout.': 317, 'doing': 318, 'me!': 319, 'give': 320, 'a+++++++!!!': 321, 'good': 322, 'friendly': 323, 'mostly': 324, 'everyone': 325, 'enjoy': 326, 'movie.': 327, 'awesome': 328, 'must': 329, 'see.': 330, 'fun': 331, 'show.': 332, 'cannot': 333, 'wait': 334, 'season': 335, '2!': 336, 'coco!': 337, 'husband': 338, '(mexican)': 339, '(caucasian)': 340, 'saw': 341, 'date': 342, 'night': 343, 'moved': 344, 'tears.': 345, 'asked': 346, 'him': 347, 'accurate': 348, 'his': 349, 'opinion': 350, 'culture': 351, 'he': 352, 'said': 353, 'was.': 354, \"can't\": 355, 'till': 356, 'comes': 357, 'daughter.': 358, 'line.': 359, 'miguel': 360, 'such': 361, 'cute': 362, 'kid': 363, 'real.<br': 364, '/><br': 365, '/>personal': 366, 'opinion:': 367, 'reading': 368, 'lower': 369, 'star': 370, 'irks': 371, 'me': 372, 'because': 373, 'culture,': 374, 'religion,': 375, 'concept.': 376, 'it,': 377, 'fine,': 378, 'base': 379, 'based': 380, 'own': 381, 'religion/culture.': 382, 'goodness': 383, 'sake,': 384, \"child's\": 385, \"i'd\": 386, 'see': 387, 'people': 388, 'review': 389, 'disney': 390, 'movies.': 391, 'sheesh.': 392, 'wish': 393, 'there': 394, 'more!': 395, 'absolutely': 396, 'everything': 397, 'miniseries.': 398, 'seasons.': 399, 'acting,': 400, 'dancing,': 401, 'music,': 402, 'storyline...perfect!': 403, 'there!': 404, \"it's\": 405, 'better': 406, 'watching': 407, 'now': 408, 'young': 409, 'child.': 410, 'now.': 411, 'pretty': 412, 'good.': 413, 'had': 414, 'comical': 415, 'scenes': 416, 'throughout.': 417, 'chick': 418, 'flick.': 419, 'anything': 420, 'there.': 421, 'series!': 422, 'witty.': 423, 'hilarious.': 424, 'raunchy.': 425, 'archer!': 426, 'wanted': 427, 'up': 428, 'theater': 429, 'made': 430, 'it.': 431, 'happy': 432, 'amazon': 433, 'rent.': 434, 'powerful': 435, 'well': 436, 'stated': 437, 'dark': 438, 'matters': 439, 'u.s.': 440, 'highly': 441, 'recommend': 442, 'movie,': 443, 'educational': 444, 'scary': 445, 'well.': 446, 'item': 447, 'canceled.': 448, '.': 449, '.no': 450, 'comments': 451, 'anime.': 452, '.have': 453, 'movie:': 454, 'seen': 455, 'good,': 456, 'go': 457, 'either': 458, 'way': 459, 'one;': 460, 'watch': 461, '-': 462, 'money.': 463, 'gift.': 464, 'kind': 465, 'low': 466, 'budget': 467, 'b': 468, \".didn't\": 469, '.the': 470, 'gave': 471, 'satified.': 472, '.he': 473, 'japanese': 474, 'animation.': 475, '.this': 476, 'money': 477, 'grew': 478, 'one.': 479, \"couldn't\": 480, 'week': 481, 'another': 482, 'episode:': 483, 'glad': 484, 'found': 485, 'collection': 486, 'classics:': 487, 'friends': 488, 'over': 489, 'times:': 490, 'acting:': 491, 'sound:': 492, 'bruce': 493, 'willis': 494, 'brings': 495, 'watching:': 496, \"haven't\": 497, 'gotten': 498, 'volumes': 499, 'yet,': 500, 'working': 501, 'it:': 502, 'entertaining:': 503, 'older': 504, 'age': 505, 'animation': 506, 'watch:': 507, 'show:': 508, 'watched': 509, 'younger:': 510, 'still': 511, 'again:': 512, 'tired': 513, 'first': 514, 'three': 515, 'sesons': 516, 'airwolf': 517, 'cool': 518, 'me,': 519, 'getting': 520, 'gift': 521, 'kids:': 522, 'keep': 523, 'entertained': 524, 'trouble': 525, 'while': 526, 'picked': 527, 'replacement': 528, 'friend:': 529, 'somewhere': 530, \"their's\": 531, 'got': 532, 'misplaced:': 533, 'gift:they': 534, 'again': 535, \"didn't\": 536, 'aired': 537, 'tv;': 538, 'pak;': 539, 'finish': 540, 'okay.': 541, '.alittle': 542, 'old': 543, 'series;': 544, 'mustang': 545, 'change;': 546, 'few': 547, 'episodes;': 548, 'disapointed': 549, 'yet;': 550, 'going': 551, 'ahead': 552, 'grown': 553, 'up,': 554, 'use': 555, 'out;': 556, 'enjoyed': 557, 'bravestar': 558, 'youth,': 559, 'man.': 560, '.glad': 561, 'full': 562, 'action.': 563, 'acting!': 564, 'slow': 565, 'unsatisfying': 566, 'could': 567, 'written': 568, 'script.': 569, 'sorry': 570, 'wasted': 571, 'fun,': 572, 'colorful,': 573, 'entertaining': 574, 'costuming': 575, 'beautiful.': 576, 'sets': 577, 'innovative.<br': 578, '/>going': 579, 'from': 580, 'kansas': 581, 'nyc': 582, 'works.': 583, 'beyond': 584, '&#34;black': 585, 'movie&#34;,': 586, 'imo&#62;.': 587, ',': 588, 'mel': 589, 'brooks': 590, 'numerous': 591, 'times': 592, 'seem': 593, 'seeing': 594, 'kid.': 595, 'add': 596, 'collection.': 597, 'details': 598, 'hd': 599, 'version.': 600, 'solely': 601, 'incest.': 602, 'garbage': 603, 'actors': 604, 'terrible.': 605, 'right': 606, 'amount': 607, 'weird.': 608, \"let's\": 609, 'forget': 610, 'cast!': 611, 'ensemble': 612, 'cast<br': 613, '/>an': 614, 'underrated': 615, 'gem<br': 616, '/>my': 617, 'sympathies': 618, 'every': 619, 'dude': 620, 'missed': 621, 'back': 622, 'day': 623, 'no': 624, 'left': 625, 'wondering': 626, '\"where': 627, 'supplemental': 628, 'materials': 629, 'are?\"<br': 630, '/>now': 631, 'thanks': 632, 'mighty': 633, 'lord': 634, 'jeff': 635, 'bezos': 636, 'glorious': 637, '480p<br': 638, '/>chinquee': 639, 'number': 640, '2': 641, 'series': 642, 'sure': 643, '3': 644, 'ranking': 645, '#1': 646, '#2': 647, 'far': 648, 'new': 649, 'follow': 650, 'grow': 651, 'develop': 652, 'part': 653, 'def': 654, 'all...': 655, 'fighting': 656, 'whole': 657, 'painful': 658, 'watch.': 659, 'year': 660, 'old.': 661, 'classic': 662, 'since': 663, 'sort': 664, 'problem': 665, 'where': 666, \"wouldn't\": 667, 'read': 668, 'would': 669, 'kick': 670, 'screen.': 671, 'issue': 672, 'blu-ray': 673, 'disk': 674, \"i've\": 675, 'continued': 676, 'same': 677, 'player': 678, 'month': 679, 'problems.': 680, 'funny': 681, 'obsevent': 682, 'time!': 683, 'entertaining...': 684, 'excellent!!!': 685, 'elizabeth': 686, 'taylor.....': 687, 'waste': 688, '1': 689, 'hearts': 690, 'hair': 691, 'looked': 692, 'beautiful...': 693, 'it??': 694, 'wig': 695, 'wears': 696, 'hideous..': 697, 'sorry...': 698, 'arrived': 699, 'packed': 700, 'watched.': 701, 'purchased': 702, 'help': 703, 'prepare': 704, 'take': 705, 'workshop': 706, 'rep': 707, 'weave': 708, 'rosalie': 709, 'neilson.': 710, 'remember': 711, 'learned': 712, 'improve': 713, 'technique.': 714, 'having': 715, 'resource.': 716, 'weaver.': 717, 'tom': 718, 'clear': 719, 'easy': 720, 'directions': 721, 'warping': 722, 'loom.': 723, 'reference': 724, 'material.': 725, 'big': 726, 'fan': 727, 'knisley.': 728, 'informative.': 729, 'providing': 730, 'instruction': 731, 'manner': 732, 'follow.': 733, 'explanation': 734, 'parts': 735, 'loom': 736, 'clean': 737, 'care': 738, 'included': 739, 'descriptions': 740, 'differences': 741, 'between': 742, 'looms.': 743, \"la's\": 744, 'interesting': 745, '&#34;could': 746, 'true?&#34;': 747, 'wonder': 748, 'research': 749, 'come': 750, 'explore': 751, 'fans.': 752, 'video,': 753, 'answers': 754, 'questions': 755, 'looking': 756, 'for.': 757, 'however,': 758, 'wished': 759, 'offered.': 760, 'it!!': 761, 'long': 762, 'acting': 763, 'wonderful': 764, \"(don't\": 765, 'believe': 766, 'reviewers)': 767, 'directing': 768, 'superb.': 769, 'fact': 770, 'movies,': 771, 'missed.': 772, 'small': 773, 'won': 774, 'sundance': 775, 'festival': 776, 'last': 777, 'year.': 778, 'great,': 779, 'high': 780, 'school/': 781, 'college': 782, 'kids!': 783, 'although': 784, 'biased': 785, '(as': 786, 'told': 787, 'palestinian': 788, 'persepective': 789, 'child),': 790, 'heartfelt': 791, 'hit': 792, 'me.': 793, 'son': 794, 'military': 795, 'kept': 796, 'thinking': 797, 'impacts': 798, '(both': 799, 'ours': 800, 'palestinian)': 801, 'innocents.': 802, 'sad': 803, 'war': 804, 'rated': 805, 'only': 806, 'stars': 807, 'because,': 808, 'athough': 809, 'photography': 810, 'spectacular,': 811, 'displays': 812, 'side': 813, 'conflict.': 814, 'shows': 815, 'rest.': 816, 'leery': 817, 'chosing': 818, 'mild': 819, 'funny.': 820, 'actually': 821, 'laughing': 822, 'most': 823, 'comedians': 824, '(most': 825, 'before).': 826, 'anyone': 827, 'dirty': 828, 'talking,': 829, 'nasty': 830, 'alternative': 831, 'entertainment': 832, 'format.': 833, 'this,': 834, 'into': 835, 'prior': 836, 'releases': 837, 'purchase': 838, 'finally': 839, 'settled': 840, 'let': 841, 'start': 842, 'saying': 843, 'mystery': 844, 'usually': 845, 'these': 846, 'say': 847, \"hasn't\": 848, 'before.': 849, 'first,': 850, 'awful.': 851, 'scripted,': 852, 'almost': 853, 'their': 854, 'lines.': 855, 'roles': 856, 'predictable': 857, '(i.e.': 858, 'token': 859, 'nationalities': 860, \"'bad\": 861, \"guy'\": 862, 'gang,': 863, 'equal': 864, 'opportunity': 865, 'offenders).': 866, 'action': 867, 'fight': 868, 'absurd.': 869, 'kim': 870, 'b.': 871, 'slinging': 872, 'tire': 873, 'iron': 874, 'someone': 875, '(and': 876, 'lodged': 877, \"victim's\": 878, 'nostrils)': 879, 'comical.': 880, 'underlying': 881, 'piece': 882, \"kim's\": 883, 'marriage': 884, 'abusive': 885, 'man,': 886, 'ridiculously': 887, 'scripted': 888, 'acted': 889, '(damn,': 890, 'housewife': 891, 'house': 892, 'junk': 893, 'filled': 894, 'did,': 895, 'yelling': 896, 'time?).': 897, 'anyway,': 898, 'reliving': 899, 'write': 900, 'painful.': 901, 'bad': 902, 'saturday': 903, 'live/madtv': 904, 'skit.': 905, 'run,': 906, 'walk,': 907, 'buying': 908, 'renting': 909, 'bought': 910, \"angela's\": 911, 'ashes': 912, 'after': 913, 'purchasing': 914, 'audio': 915, 'cd': 916, 'book': 917, '(which': 918, 'highly,': 919, 'recommend).': 920, 'starting': 921, 'audion': 922, 'cd,': 923, 'enthralled': 924, 'listening': 925, 'frank': 926, \"mccourt's\": 927, 'voice': 928, '(almost': 929, 'telling': 930, 'childhood': 931, 'me).': 932, 'disappointed': 933, 'ended': 934, '(because': 935, 'captivated),': 936, 'so,': 937, 'now,': 938, 'strengths': 939, 'beautifulm': 940, 'tragic,': 941, 'mccourts': 942, 'came': 943, 'from.': 944, 'seemed': 945, 'depressing.': 946, 'raining': 947, 'constantly': 948, 'know': 949, 'does': 950, 'frequently': 951, 'ireland,': 952, 'talked': 953, 'days': 954, 'sunshine.': 955, 'creator/director': 956, 'trying': 957, 'awfully': 958, 'hard': 959, 'similar': 960, 'living': 961, 'abusive/prison': 962, 'setting.': 963, 'loud': 964, 'tragic': 965, 'life,': 966, 'inserted': 967, 'phenominal': 968, 'sense': 969, 'humor': 970, 'everything.': 971, 'discussed': 972, 'glossed': 973, 'together.': 974, 'hearing': 975, 'felt': 976, 'enlightened,': 977, 'enchanted,': 978, 'craving': 979, 'hear': 980, 'life': 981, '(so,': 982, \"'tis\": 983, 'week).': 984, 'cry': 985, 'knees': 986, 'thank': 987, 'god': 988, \"wasn't\": 989, 'raised': 990, 'area': 991, 'ireland': 992, 'during': 993, \"1940's.\": 994, 'read/are': 995, 'real': 996, 'able': 997, 'relate': 998, 'town': 999, 'scenery': 1000, 'hear/read': 1001, 'book.': 1002, 'relatable': 1003, '(despite': 1004, 'otherworldly': 1005, 'challenges)': 1006, 'witty': 1007, 'humor,': 1008, 'being': 1009, 'human': 1010, 'entertaining,': 1011, 'intriguing': 1012, 'satisfying.': 1013, 'starts': 1014, 'break': 1015, 'apart': 1016, 'here': 1017, 'arc': 1018, 'goes': 1019, 'weird': 1020, 'unbelievable.': 1021, 'wracking': 1022, 'brain': 1023, 'against': 1024, 'episode': 1025, 'form': 1026, 'entertainment.': 1027, 'loves': 1028, 'nice': 1029, 'find': 1030, 'disc': 1031, 'binge-': 1032, '8': 1033, 'weekend.': 1034, '2üëçüèº': 1035, 'perfect,': 1036, 'nice,': 1037, 'girls!': 1038, 'forward': 1039, ':)': 1040, 'writing-': 1041, 'believable': 1042, 'dialogue-': 1043, 'actors!': 1044, 'five': 1045, 'stars!üëç': 1046, 'coolest': 1047, 'thumbs': 1048, 'up!': 1049, 'emmy': 1050, 'award': 1051, 'winning': 1052, 'kids...': 1053, 'maybe': 1054, '10-15': 1055, 'ish..': 1056, 'stories': 1057, 'done!': 1058, 'available!': 1059, 'dvr': 1060, 'like.': 1061, 'latest': 1062, 'lot,': 1063, 'took': 1064, 'awhile': 1065, 'remember<br': 1066, '/>how': 1067, 'stand': 1068, 'remade': 1069, 'nothing': 1070, 'original.': 1071, 'fine': 1072, 'want': 1073, 'name': 1074, 'earned': 1075, 'reputation.': 1076, 'comparing': 1077, 'original': 1078, 'remake': 1079, 'starred': 1080, 'steve': 1081, 'martin.': 1082, 'excited': 1083, 'cast': 1084, 'premise': 1085, 'boring': 1086, 'acting.': 1087, 'fell': 1088, 'asleep!': 1089, 'woke': 1090, 'half': 1091, 'hour': 1092, 'playing': 1093, 'happened.': 1094, 'also,': 1095, 'stop': 1096, 'using': 1097, 'from,': 1098, 'insulting.': 1099, 'hollywood': 1100, 'this?': 1101, 'one,': 1102, 'final': 1103, 'air?': 1104, 'several': 1105, 'weeks': 1106, '16th': 1107, 'be.<br': 1108, '/>while': 1109, 'end': 1110, 'result,': 1111, 'anymore.': 1112, 'ben': 1113, 'become': 1114, 'screw': 1115, 'around': 1116, 'act': 1117, 'kids.': 1118, 'funny,': 1119, 'annoying.': 1120, 'longer': 1121, 'erin,': 1122, 'irritating': 1123, 'overdone': 1124, 'accent': 1125, 'lot': 1126, 'says': 1127, 'awkward': 1128, 'unenjoyable': 1129, 'hgtv': 1130, 'much.': 1131, 'change': 1132, 'alls': 1133, 'unbearable': 1134, 'becomes': 1135, 'network.': 1136, 'current': 1137, 'air,': 1138, 'next': 1139, 'airs': 1140, 'hallmark': 1141, 'channel.': 1142, 'release': 1143, 'timely': 1144, 'manner,': 1145, 'waiting': 1146, 'morning.': 1147, 'rarely': 1148, 'networks': 1149, 'do.<br': 1150, '/>as': 1151, 'show,': 1152, 'terrible': 1153, 'season!': 1154, 'us': 1155, 'negativity': 1156, 'female': 1157, 'season.': 1158, 'couple‚Äôs': 1159, 'clara': 1160, 'angry': 1161, 'jesse': 1162, 'faith': 1163, 'making': 1164, 'carson': 1165, 'knows': 1166, 'keeps': 1167, 'messing': 1168, 'up.': 1169, \"elizabeth's\": 1170, 'unlikeable': 1171, 'point.': 1172, 'rude,': 1173, 'bitter': 1174, 'unpleasant.': 1175, 'triangle': 1176, 'gets': 1177, 'they‚Äôve': 1178, 'cares': 1179, 'point': 1180, 'picks': 1181, 'happens': 1182, 'character?': 1183, 'tried': 1184, 'horrible.': 1185, 'laugh': 1186, 'track': 1187, 'ridiculous': 1188, 'less': 1189, 'fake': 1190, 'laughter': 1191, 'it‚Äôd': 1192, 'tolerable.': 1193, 'guess': 1194, 'okay': 1195, 'personally': 1196, 'needless': 1197, 'say,': 1198} index\n",
      "0                                 [0, 1, 2, 3, 4, 5, 6]\n",
      "1                                     [7, 8, 9, 10, 11]\n",
      "2     [12, 13, 14, 15, 16, 17, 18, 15, 19, 20, 21, 2...\n",
      "3     [86, 87, 88, 89, 20, 21, 90, 20, 91, 18, 92, 9...\n",
      "4     [130, 131, 132, 133, 134, 53, 66, 135, 59, 136...\n",
      "                            ...                        \n",
      "95    [231, 432, 3, 1062, 335, 82, 1059, 103, 233, 1...\n",
      "96    [103, 333, 1068, 136, 200, 251, 1069, 25, 177,...\n",
      "97    [212, 1102, 136, 82, 3, 1103, 1025, 551, 66, 1...\n",
      "98    [231, 212, 140, 20, 118, 28, 238, 117, 908, 3,...\n",
      "99    [103, 279, 308, 377, 103, 1184, 66, 52, 10, 12...\n",
      "Name: token_index, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# pipeline = Pipeline()\n",
    "\n",
    "\n",
    "vocabulary, processed_tokens = preprocess(text_data)\n",
    "\n",
    "print(vocabulary, processed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 0)\t1\n",
      "  (1, 111)\t1\n",
      "  (2, 221)\t1\n",
      "  (2, 232)\t1\n",
      "  (2, 243)\t1\n",
      "  (2, 254)\t4\n",
      "  (2, 265)\t1\n",
      "  (2, 276)\t1\n",
      "  (2, 287)\t4\n",
      "  (2, 298)\t1\n",
      "  (2, 309)\t5\n",
      "  (2, 320)\t3\n",
      "  (2, 331)\t1\n",
      "  (2, 342)\t1\n",
      "  (2, 353)\t1\n",
      "  (2, 364)\t4\n",
      "  (2, 375)\t1\n",
      "  (2, 386)\t1\n",
      "  (2, 397)\t2\n",
      "  (2, 408)\t1\n",
      "  (2, 419)\t1\n",
      "  (2, 430)\t1\n",
      "  (2, 441)\t1\n",
      "  (2, 452)\t1\n",
      "  (2, 463)\t2\n",
      "  :\t:\n",
      "  (99, 323)\t1\n",
      "  (99, 344)\t1\n",
      "  (99, 396)\t1\n",
      "  (99, 428)\t1\n",
      "  (99, 504)\t1\n",
      "  (99, 523)\t1\n",
      "  (99, 929)\t1\n",
      "  (99, 962)\t1\n",
      "  (99, 995)\t1\n",
      "  (99, 61)\t1\n",
      "  (99, 205)\t1\n",
      "  (99, 206)\t1\n",
      "  (99, 207)\t1\n",
      "  (99, 208)\t1\n",
      "  (99, 209)\t1\n",
      "  (99, 210)\t1\n",
      "  (99, 212)\t1\n",
      "  (99, 213)\t1\n",
      "  (99, 214)\t1\n",
      "  (99, 215)\t1\n",
      "  (99, 216)\t1\n",
      "  (99, 217)\t1\n",
      "  (99, 218)\t1\n",
      "  (99, 219)\t1\n",
      "  (99, 220)\t1 \n",
      " ['10' '100' '1000' ... '997' '998' '999']\n"
     ]
    }
   ],
   "source": [
    "encoded, feature_names = encode(processed_tokens, method='bow')\n",
    "print(encoded, '\\n', feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 44)\t1\n",
      "  (0, 636)\t1\n",
      "  (0, 134)\t1\n",
      "  (0, 816)\t1\n",
      "  (0, 752)\t1\n",
      "  (0, 398)\t1\n",
      "  (1, 752)\t1\n",
      "  (1, 560)\t1\n",
      "  (1, 460)\t1\n",
      "  (1, 503)\t1\n",
      "  (1, 828)\t1\n",
      "  (2, 816)\t4\n",
      "  (2, 503)\t1\n",
      "  (2, 53)\t1\n",
      "  (2, 726)\t1\n",
      "  (2, 217)\t1\n",
      "  (2, 383)\t4\n",
      "  (2, 151)\t1\n",
      "  (2, 453)\t1\n",
      "  (2, 930)\t4\n",
      "  (2, 640)\t1\n",
      "  (2, 589)\t5\n",
      "  (2, 528)\t1\n",
      "  (2, 411)\t1\n",
      "  (2, 209)\t1\n",
      "  :\t:\n",
      "  (99, 545)\t1\n",
      "  (99, 152)\t1\n",
      "  (99, 233)\t1\n",
      "  (99, 315)\t1\n",
      "  (99, 764)\t1\n",
      "  (99, 238)\t1\n",
      "  (99, 337)\t1\n",
      "  (99, 525)\t1\n",
      "  (99, 17)\t1\n",
      "  (99, 593)\t1\n",
      "  (99, 547)\t1\n",
      "  (99, 718)\t1\n",
      "  (99, 522)\t1\n",
      "  (99, 859)\t1\n",
      "  (99, 400)\t1\n",
      "  (99, 471)\t1\n",
      "  (99, 855)\t1\n",
      "  (99, 702)\t1\n",
      "  (99, 479)\t1\n",
      "  (99, 286)\t1\n",
      "  (99, 473)\t1\n",
      "  (99, 848)\t1\n",
      "  (99, 359)\t1\n",
      "  (99, 626)\t1\n",
      "  (99, 566)\t1 \n",
      " ['10' '15' '16th' '1940' '34' '480p' '62' 'abandoned' 'able' 'about'\n",
      " 'absolutely' 'absurd' 'abusive' 'accent' 'accurate' 'act' 'acted'\n",
      " 'acting' 'action' 'actions' 'actors' 'actually' 'add' 'addiction' 'after'\n",
      " 'again' 'against' 'age' 'ahead' 'air' 'aired' 'airs' 'airwolf' 'alittle'\n",
      " 'all' 'alls' 'almost' 'alot' 'also' 'alternative' 'although' 'always'\n",
      " 'am' 'amazing' 'amazon' 'amount' 'an' 'analyze' 'and' 'angela' 'angry'\n",
      " 'animation' 'anime' 'annabella' 'annoying' 'another' 'answers' 'any'\n",
      " 'anymore' 'anyone' 'anything' 'anyway' 'apart' 'arc' 'archer' 'are'\n",
      " 'area' 'areas' 'around' 'arrived' 'as' 'ashes' 'asked' 'asleep' 'at'\n",
      " 'athough' 'audio' 'audion' 'autism' 'available' 'award' 'awesome' 'awful'\n",
      " 'awfully' 'awhile' 'awkward' 'back' 'bad' 'base' 'based' 'be' 'beautiful'\n",
      " 'beautifulm' 'because' 'become' 'becomes' 'been' 'before' 'beginner'\n",
      " 'behind' 'being' 'believable' 'believe' 'ben' 'best' 'better' 'between'\n",
      " 'beyond' 'bezos' 'biased' 'big' 'bill' 'binge' 'bit' 'bitter' 'black'\n",
      " 'blu' 'body' 'book' 'boring' 'both' 'bought' 'boy' 'br' 'brain'\n",
      " 'bravestar' 'break' 'bring' 'brings' 'broken' 'brooks' 'bruce' 'budget'\n",
      " 'but' 'buy' 'buying' 'by' 'came' 'can' 'canceled' 'cannot' 'captivated'\n",
      " 'care' 'cares' 'carson' 'cast' 'caucasian' 'cd' 'challenges' 'change'\n",
      " 'channel' 'character' 'characters' 'chick' 'child' 'childhood' 'chinquee'\n",
      " 'chosing' 'clara' 'classic' 'classics' 'clean' 'clear' 'closest'\n",
      " 'closure' 'coco' 'collection' 'college' 'color' 'colorful' 'come'\n",
      " 'comedians' 'comes' 'comforting' 'comical' 'comments' 'comparing'\n",
      " 'complements' 'complex' 'concept' 'conflict' 'constantly' 'continued'\n",
      " 'cool' 'coolest' 'costuming' 'could' 'couldn' 'couple' 'craving'\n",
      " 'creator' 'cry' 'culture' 'current' 'cute' 'damn' 'dancing' 'dark' 'date'\n",
      " 'daughter' 'day' 'days' 'dear' 'decent' 'deep' 'deeper' 'def'\n",
      " 'definitely' 'depict' 'depressed' 'depressing' 'depth' 'descriptions'\n",
      " 'despite' 'details' 'develop' 'dialogue' 'did' 'didn' 'differences'\n",
      " 'different' 'directing' 'directions' 'director' 'dirty' 'disapointed'\n",
      " 'disappointed' 'disc' 'discussed' 'disk' 'disney' 'displays' 'diverse'\n",
      " 'do' 'documentary' 'does' 'doesn' 'doing' 'don' 'done' 'dude' 'during'\n",
      " 'dvd' 'dvr' 'each' 'earned' 'easier' 'easy' 'educational' 'either'\n",
      " 'elizabeth' 'else' 'emmy' 'emotions' 'enchanted' 'end' 'ended' 'ending'\n",
      " 'enjoy' 'enjoyed' 'enlightened' 'enough' 'ensemble' 'entertained'\n",
      " 'entertaining' 'entertainment' 'enthralled' 'episode' 'episodes' 'equal'\n",
      " 'erin' 'even' 'every' 'everyone' 'everything' 'excellent' 'excited'\n",
      " 'exciting' 'expect' 'explanation' 'explore' 'fabulous' 'faced' 'faces'\n",
      " 'fact' 'faith' 'fake' 'falls' 'family' 'fan' 'fans' 'far' 'father' 'feel'\n",
      " 'feels' 'fell' 'felt' 'female' 'festival' 'few' 'fight' 'fighting'\n",
      " 'filled' 'film' 'films' 'final' 'finally' 'find' 'fine' 'finish' 'first'\n",
      " 'fits' 'five' 'flick' 'follow' 'for' 'forget' 'forgotten' 'form' 'format'\n",
      " 'forward' 'found' 'frank' 'frequently' 'friend' 'friendly' 'friends'\n",
      " 'from' 'full' 'fun' 'functioning' 'funny' 'future' 'gang' 'garbage'\n",
      " 'gave' 'gem' 'get' 'gets' 'getting' 'gift' 'girls' 'give' 'gives' 'glad'\n",
      " 'glorious' 'glossed' 'go' 'god' 'goes' 'going' 'good' 'goodness' 'got'\n",
      " 'gotten' 'great' 'grew' 'grow' 'grown' 'guess' 'guy' 'had' 'hair' 'half'\n",
      " 'hallmark' 'happened' 'happens' 'happy' 'hard' 'harsh' 'has' 'hasn'\n",
      " 'have' 'haven' 'having' 'hd' 'he' 'hear' 'hearing' 'heartfelt' 'hearts'\n",
      " 'heartwarming' 'help' 'her' 'here' 'hgtv' 'hideous' 'high' 'highly'\n",
      " 'hilarious' 'him' 'his' 'hit' 'hits' 'hold' 'hollywood' 'home' 'honestly'\n",
      " 'hooked' 'hope' 'horrible' 'hour' 'house' 'housewife' 'how' 'however'\n",
      " 'hp' 'human' 'humor' 'husband' 'if' 'ill' 'imo' 'impact' 'impacts'\n",
      " 'improve' 'in' 'incest' 'included' 'independent' 'individual'\n",
      " 'individually' 'informative' 'inner' 'innocents' 'innovative' 'inserted'\n",
      " 'inspires' 'instruction' 'insulting' 'interesting' 'into' 'intriguing'\n",
      " 'ireland' 'irks' 'iron' 'irritating' 'is' 'ish' 'isn' 'issue' 'it' 'item'\n",
      " 'its' 'jack' 'japanese' 'jason' 'jeff' 'jennifer' 'jesse' 'jesus' 'junk'\n",
      " 'just' 'justice' 'kansas' 'keep' 'keeps' 'kept' 'kick' 'kid' 'kiddos'\n",
      " 'kids' 'kim' 'kind' 'knees' 'knisley' 'know' 'knows' 'la' 'last' 'latest'\n",
      " 'laugh' 'laughing' 'laughter' 'learn' 'learned' 'leery' 'left' 'legit'\n",
      " 'less' 'let' 'life' 'light' 'like' 'liked' 'likes' 'line' 'lines'\n",
      " 'listening' 'little' 'live' 'living' 'lodged' 'long' 'longer' 'looked'\n",
      " 'looking' 'loom' 'looms' 'lord' 'loss' 'lot' 'loud' 'love' 'loved'\n",
      " 'loves' 'low' 'lower' 'made' 'madtv' 'magic' 'make' 'makes' 'making'\n",
      " 'man' 'manner' 'many' 'marriage' 'martin' 'material' 'materials'\n",
      " 'matters' 'maybe' 'mccourt' 'mccourts' 'me' 'mel' 'memories' 'mentally'\n",
      " 'menu' 'messing' 'mexican' 'might' 'mighty' 'miguel' 'mild' 'military'\n",
      " 'miniseries' 'minute' 'misplaced' 'missed' 'mom' 'moments' 'money'\n",
      " 'month' 'more' 'morning' 'most' 'mostly' 'mother' 'motivate' 'moved'\n",
      " 'moves' 'movie' 'movies' 'moving' 'much' 'music' 'must' 'mustang' 'my'\n",
      " 'myself' 'mystery' 'name' 'nasty' 'nationalities' 'needless' 'negativity'\n",
      " 'neighbor' 'neilson' 'network' 'networks' 'never' 'new' 'next' 'nice'\n",
      " 'night' 'no' 'nobody' 'nostrils' 'not' 'nothing' 'notice' 'now' 'number'\n",
      " 'numerous' 'nyc' 'obsessed' 'obsevent' 'of' 'offenders' 'offered' 'often'\n",
      " 'okay' 'old' 'older' 'on' 'one' 'only' 'onto' 'opinion' 'opportunity'\n",
      " 'option' 'or' 'original' 'other' 'others' 'otherworldly' 'our' 'ours'\n",
      " 'out' 'over' 'overdone' 'own' 'packed' 'painful' 'pak' 'palestinian'\n",
      " 'part' 'parts' 'people' 'perfect' 'persepective' 'person' 'personal'\n",
      " 'personalizing' 'personally' 'phenominal' 'photography' 'picked' 'picks'\n",
      " 'piece' 'pilates' 'play' 'player' 'playing' 'please' 'plus' 'poetic'\n",
      " 'point' 'portrayal' 'portrayed' 'potential' 'powerful' 'predictable'\n",
      " 'premise' 'prepare' 'pretty' 'previews' 'prior' 'prison' 'problem'\n",
      " 'problems' 'procrastinating' 'projects' 'providing' 'psychic' 'pulls'\n",
      " 'purchase' 'purchased' 'purchasing' 'questions' 'quite' 'raining'\n",
      " 'raised' 'range' 'ranking' 'rarely' 'rated' 'raunchy' 'ray' 're' 'read'\n",
      " 'reading' 'real' 'really' 'recommend' 'reference' 'relatable' 'relate'\n",
      " 'release' 'releases' 'religion' 'reliving' 'remade' 'remake' 'remember'\n",
      " 'reminding' 'rent' 'renting' 'rep' 'replacement' 'representation'\n",
      " 'reputation' 'research' 'resonate' 'resource' 'rest' 'result' 'review'\n",
      " 'reviewers' 'reviews' 'ridiculous' 'ridiculously' 'right' 'roles'\n",
      " 'rosalie' 'rough' 'rude' 'run' 'sad' 'said' 'sake' 'same' 'satified'\n",
      " 'satisfying' 'saturday' 'saw' 'say' 'saying' 'says' 'scale' 'scary'\n",
      " 'scenery' 'scenes' 'school' 'sciorra' 'screen' 'screw' 'script'\n",
      " 'scripted' 'season' 'seasons' 'see' 'seeing' 'seem' 'seemed' 'seems'\n",
      " 'seen' 'sense' 'sensitively' 'series' 'sesons' 'sets' 'setting' 'settled'\n",
      " 'several' 'severe' 'shape' 'she' 'sheesh' 'should' 'show' 'shows' 'side'\n",
      " 'similar' 'simple' 'since' 'sit' 'skit' 'slinging' 'slow' 'small' 'smile'\n",
      " 'so' 'socially' 'solely' 'some' 'someone' 'somewhat' 'somewhere' 'son'\n",
      " 'sorry' 'sort' 'sound' 'spectacular' 'spectrum' 'stand' 'star' 'starred'\n",
      " 'stars' 'start' 'starting' 'starts' 'stated' 'stay' 'steve' 'still'\n",
      " 'stop' 'stories' 'story' 'storyline' 'strengths' 'struggles' 'such'\n",
      " 'sundance' 'sunshine' 'super' 'superb' 'supplemental' 'sure' 'sweet'\n",
      " 'sympathies' 'take' 'talked' 'talking' 'targets' 'taylor' 'tears'\n",
      " 'technique' 'telling' 'terrible' 'than' 'thank' 'thanks' 'that' 'the'\n",
      " 'theater' 'their' 'them' 'then' 'there' 'these' 'they' 'thing' 'things'\n",
      " 'think' 'thinking' 'this' 'those' 'though' 'thought' 'three' 'through'\n",
      " 'throughout' 'thumbs' 'tie' 'till' 'time' 'timely' 'times' 'tire' 'tired'\n",
      " 'tis' 'to' 'together' 'token' 'told' 'tolerable' 'tom' 'ton' 'too' 'took'\n",
      " 'totally' 'town' 'track' 'tragic' 'traumatized' 'triangle' 'tried'\n",
      " 'triumph' 'trouble' 'true' 'trying' 'tv' 'type' 'unbearable'\n",
      " 'unbelievable' 'underlying' 'underrated' 'understand' 'understanding'\n",
      " 'unenjoyable' 'unique' 'unlikeable' 'unpleasant' 'unsatisfying' 'up' 'us'\n",
      " 'use' 'using' 'usually' 'values' 've' 'version' 'very' 'victim' 'video'\n",
      " 'visual' 'voice' 'volumes' 'wait' 'waiting' 'walk' 'want' 'wanted' 'war'\n",
      " 'warping' 'was' 'wasn' 'waste' 'wasted' 'watch' 'watched' 'watching'\n",
      " 'way' 'we' 'wears' 'weave' 'weaver' 'week' 'weekend' 'weeks' 'weird'\n",
      " 'well' 'were' 'what' 'when' 'where' 'which' 'while' 'who' 'whole' 'whom'\n",
      " 'wig' 'will' 'willis' 'winning' 'wish' 'wished' 'with' 'within' 'witty'\n",
      " 'woke' 'won' 'wonder' 'wonderful' 'wondering' 'woodlawn' 'words'\n",
      " 'working' 'workout' 'workouts' 'works' 'workshop' 'worth' 'would'\n",
      " 'wouldn' 'wounds' 'wracking' 'write' 'writing' 'written' 'year' 'yelling'\n",
      " 'yet' 'you' 'young' 'younger' 'your' 'youth']\n"
     ]
    }
   ],
   "source": [
    "encoded, feature_names = encode(text_data, method='bow')\n",
    "print(encoded, '\\n', feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 398)\t0.5075127547381553\n",
      "  (0, 752)\t0.2753783597774882\n",
      "  (0, 816)\t0.1696009788135251\n",
      "  (0, 134)\t0.43604121049961136\n",
      "  (0, 636)\t0.5075127547381553\n",
      "  (0, 44)\t0.43604121049961136\n",
      "  (1, 828)\t0.2418939435569401\n",
      "  (1, 503)\t0.41289632458447334\n",
      "  (1, 460)\t0.6990765545816118\n",
      "  (1, 560)\t0.3720363324057197\n",
      "  (1, 752)\t0.3793216094813328\n",
      "  (2, 173)\t0.10864539579717775\n",
      "  (2, 769)\t0.10864539579717775\n",
      "  (2, 38)\t0.08439512892755482\n",
      "  (2, 437)\t0.04886913009321406\n",
      "  (2, 919)\t0.08841961186293022\n",
      "  (2, 293)\t0.09334518089708448\n",
      "  (2, 419)\t0.10864539579717775\n",
      "  (2, 370)\t0.07804496599699122\n",
      "  (2, 19)\t0.10864539579717775\n",
      "  (2, 47)\t0.10864539579717775\n",
      "  (2, 603)\t0.0809924770889551\n",
      "  (2, 902)\t0.06014486205793193\n",
      "  (2, 620)\t0.08841961186293022\n",
      "  (2, 485)\t0.10864539579717775\n",
      "  :\t:\n",
      "  (99, 17)\t0.12272956973430107\n",
      "  (99, 525)\t0.1130089632586866\n",
      "  (99, 337)\t0.11026325993100881\n",
      "  (99, 238)\t0.1266331810468259\n",
      "  (99, 764)\t0.11597454877436761\n",
      "  (99, 315)\t0.08328199441122482\n",
      "  (99, 233)\t0.13099704722137054\n",
      "  (99, 152)\t0.13099704722137054\n",
      "  (99, 545)\t0.12272956973430107\n",
      "  (99, 90)\t0.11026325993100881\n",
      "  (99, 821)\t0.1130089632586866\n",
      "  (99, 437)\t0.246077821703511\n",
      "  (99, 410)\t0.12272956973430107\n",
      "  (99, 844)\t0.13737564979168915\n",
      "  (99, 133)\t0.18703438609406262\n",
      "  (99, 580)\t0.11026325993100881\n",
      "  (99, 898)\t0.08081107632283649\n",
      "  (99, 441)\t0.18282289630632328\n",
      "  (99, 483)\t0.20613954368532786\n",
      "  (99, 439)\t0.1566781779408317\n",
      "  (99, 48)\t0.06783606232757014\n",
      "  (99, 589)\t0.07738864112320276\n",
      "  (99, 828)\t0.1261996616166186\n",
      "  (99, 752)\t0.19789771524042737\n",
      "  (99, 816)\t0.18282289630632328 \n",
      " ['10' '15' '16th' '1940' '34' '480p' '62' 'abandoned' 'able' 'about'\n",
      " 'absolutely' 'absurd' 'abusive' 'accent' 'accurate' 'act' 'acted'\n",
      " 'acting' 'action' 'actions' 'actors' 'actually' 'add' 'addiction' 'after'\n",
      " 'again' 'against' 'age' 'ahead' 'air' 'aired' 'airs' 'airwolf' 'alittle'\n",
      " 'all' 'alls' 'almost' 'alot' 'also' 'alternative' 'although' 'always'\n",
      " 'am' 'amazing' 'amazon' 'amount' 'an' 'analyze' 'and' 'angela' 'angry'\n",
      " 'animation' 'anime' 'annabella' 'annoying' 'another' 'answers' 'any'\n",
      " 'anymore' 'anyone' 'anything' 'anyway' 'apart' 'arc' 'archer' 'are'\n",
      " 'area' 'areas' 'around' 'arrived' 'as' 'ashes' 'asked' 'asleep' 'at'\n",
      " 'athough' 'audio' 'audion' 'autism' 'available' 'award' 'awesome' 'awful'\n",
      " 'awfully' 'awhile' 'awkward' 'back' 'bad' 'base' 'based' 'be' 'beautiful'\n",
      " 'beautifulm' 'because' 'become' 'becomes' 'been' 'before' 'beginner'\n",
      " 'behind' 'being' 'believable' 'believe' 'ben' 'best' 'better' 'between'\n",
      " 'beyond' 'bezos' 'biased' 'big' 'bill' 'binge' 'bit' 'bitter' 'black'\n",
      " 'blu' 'body' 'book' 'boring' 'both' 'bought' 'boy' 'br' 'brain'\n",
      " 'bravestar' 'break' 'bring' 'brings' 'broken' 'brooks' 'bruce' 'budget'\n",
      " 'but' 'buy' 'buying' 'by' 'came' 'can' 'canceled' 'cannot' 'captivated'\n",
      " 'care' 'cares' 'carson' 'cast' 'caucasian' 'cd' 'challenges' 'change'\n",
      " 'channel' 'character' 'characters' 'chick' 'child' 'childhood' 'chinquee'\n",
      " 'chosing' 'clara' 'classic' 'classics' 'clean' 'clear' 'closest'\n",
      " 'closure' 'coco' 'collection' 'college' 'color' 'colorful' 'come'\n",
      " 'comedians' 'comes' 'comforting' 'comical' 'comments' 'comparing'\n",
      " 'complements' 'complex' 'concept' 'conflict' 'constantly' 'continued'\n",
      " 'cool' 'coolest' 'costuming' 'could' 'couldn' 'couple' 'craving'\n",
      " 'creator' 'cry' 'culture' 'current' 'cute' 'damn' 'dancing' 'dark' 'date'\n",
      " 'daughter' 'day' 'days' 'dear' 'decent' 'deep' 'deeper' 'def'\n",
      " 'definitely' 'depict' 'depressed' 'depressing' 'depth' 'descriptions'\n",
      " 'despite' 'details' 'develop' 'dialogue' 'did' 'didn' 'differences'\n",
      " 'different' 'directing' 'directions' 'director' 'dirty' 'disapointed'\n",
      " 'disappointed' 'disc' 'discussed' 'disk' 'disney' 'displays' 'diverse'\n",
      " 'do' 'documentary' 'does' 'doesn' 'doing' 'don' 'done' 'dude' 'during'\n",
      " 'dvd' 'dvr' 'each' 'earned' 'easier' 'easy' 'educational' 'either'\n",
      " 'elizabeth' 'else' 'emmy' 'emotions' 'enchanted' 'end' 'ended' 'ending'\n",
      " 'enjoy' 'enjoyed' 'enlightened' 'enough' 'ensemble' 'entertained'\n",
      " 'entertaining' 'entertainment' 'enthralled' 'episode' 'episodes' 'equal'\n",
      " 'erin' 'even' 'every' 'everyone' 'everything' 'excellent' 'excited'\n",
      " 'exciting' 'expect' 'explanation' 'explore' 'fabulous' 'faced' 'faces'\n",
      " 'fact' 'faith' 'fake' 'falls' 'family' 'fan' 'fans' 'far' 'father' 'feel'\n",
      " 'feels' 'fell' 'felt' 'female' 'festival' 'few' 'fight' 'fighting'\n",
      " 'filled' 'film' 'films' 'final' 'finally' 'find' 'fine' 'finish' 'first'\n",
      " 'fits' 'five' 'flick' 'follow' 'for' 'forget' 'forgotten' 'form' 'format'\n",
      " 'forward' 'found' 'frank' 'frequently' 'friend' 'friendly' 'friends'\n",
      " 'from' 'full' 'fun' 'functioning' 'funny' 'future' 'gang' 'garbage'\n",
      " 'gave' 'gem' 'get' 'gets' 'getting' 'gift' 'girls' 'give' 'gives' 'glad'\n",
      " 'glorious' 'glossed' 'go' 'god' 'goes' 'going' 'good' 'goodness' 'got'\n",
      " 'gotten' 'great' 'grew' 'grow' 'grown' 'guess' 'guy' 'had' 'hair' 'half'\n",
      " 'hallmark' 'happened' 'happens' 'happy' 'hard' 'harsh' 'has' 'hasn'\n",
      " 'have' 'haven' 'having' 'hd' 'he' 'hear' 'hearing' 'heartfelt' 'hearts'\n",
      " 'heartwarming' 'help' 'her' 'here' 'hgtv' 'hideous' 'high' 'highly'\n",
      " 'hilarious' 'him' 'his' 'hit' 'hits' 'hold' 'hollywood' 'home' 'honestly'\n",
      " 'hooked' 'hope' 'horrible' 'hour' 'house' 'housewife' 'how' 'however'\n",
      " 'hp' 'human' 'humor' 'husband' 'if' 'ill' 'imo' 'impact' 'impacts'\n",
      " 'improve' 'in' 'incest' 'included' 'independent' 'individual'\n",
      " 'individually' 'informative' 'inner' 'innocents' 'innovative' 'inserted'\n",
      " 'inspires' 'instruction' 'insulting' 'interesting' 'into' 'intriguing'\n",
      " 'ireland' 'irks' 'iron' 'irritating' 'is' 'ish' 'isn' 'issue' 'it' 'item'\n",
      " 'its' 'jack' 'japanese' 'jason' 'jeff' 'jennifer' 'jesse' 'jesus' 'junk'\n",
      " 'just' 'justice' 'kansas' 'keep' 'keeps' 'kept' 'kick' 'kid' 'kiddos'\n",
      " 'kids' 'kim' 'kind' 'knees' 'knisley' 'know' 'knows' 'la' 'last' 'latest'\n",
      " 'laugh' 'laughing' 'laughter' 'learn' 'learned' 'leery' 'left' 'legit'\n",
      " 'less' 'let' 'life' 'light' 'like' 'liked' 'likes' 'line' 'lines'\n",
      " 'listening' 'little' 'live' 'living' 'lodged' 'long' 'longer' 'looked'\n",
      " 'looking' 'loom' 'looms' 'lord' 'loss' 'lot' 'loud' 'love' 'loved'\n",
      " 'loves' 'low' 'lower' 'made' 'madtv' 'magic' 'make' 'makes' 'making'\n",
      " 'man' 'manner' 'many' 'marriage' 'martin' 'material' 'materials'\n",
      " 'matters' 'maybe' 'mccourt' 'mccourts' 'me' 'mel' 'memories' 'mentally'\n",
      " 'menu' 'messing' 'mexican' 'might' 'mighty' 'miguel' 'mild' 'military'\n",
      " 'miniseries' 'minute' 'misplaced' 'missed' 'mom' 'moments' 'money'\n",
      " 'month' 'more' 'morning' 'most' 'mostly' 'mother' 'motivate' 'moved'\n",
      " 'moves' 'movie' 'movies' 'moving' 'much' 'music' 'must' 'mustang' 'my'\n",
      " 'myself' 'mystery' 'name' 'nasty' 'nationalities' 'needless' 'negativity'\n",
      " 'neighbor' 'neilson' 'network' 'networks' 'never' 'new' 'next' 'nice'\n",
      " 'night' 'no' 'nobody' 'nostrils' 'not' 'nothing' 'notice' 'now' 'number'\n",
      " 'numerous' 'nyc' 'obsessed' 'obsevent' 'of' 'offenders' 'offered' 'often'\n",
      " 'okay' 'old' 'older' 'on' 'one' 'only' 'onto' 'opinion' 'opportunity'\n",
      " 'option' 'or' 'original' 'other' 'others' 'otherworldly' 'our' 'ours'\n",
      " 'out' 'over' 'overdone' 'own' 'packed' 'painful' 'pak' 'palestinian'\n",
      " 'part' 'parts' 'people' 'perfect' 'persepective' 'person' 'personal'\n",
      " 'personalizing' 'personally' 'phenominal' 'photography' 'picked' 'picks'\n",
      " 'piece' 'pilates' 'play' 'player' 'playing' 'please' 'plus' 'poetic'\n",
      " 'point' 'portrayal' 'portrayed' 'potential' 'powerful' 'predictable'\n",
      " 'premise' 'prepare' 'pretty' 'previews' 'prior' 'prison' 'problem'\n",
      " 'problems' 'procrastinating' 'projects' 'providing' 'psychic' 'pulls'\n",
      " 'purchase' 'purchased' 'purchasing' 'questions' 'quite' 'raining'\n",
      " 'raised' 'range' 'ranking' 'rarely' 'rated' 'raunchy' 'ray' 're' 'read'\n",
      " 'reading' 'real' 'really' 'recommend' 'reference' 'relatable' 'relate'\n",
      " 'release' 'releases' 'religion' 'reliving' 'remade' 'remake' 'remember'\n",
      " 'reminding' 'rent' 'renting' 'rep' 'replacement' 'representation'\n",
      " 'reputation' 'research' 'resonate' 'resource' 'rest' 'result' 'review'\n",
      " 'reviewers' 'reviews' 'ridiculous' 'ridiculously' 'right' 'roles'\n",
      " 'rosalie' 'rough' 'rude' 'run' 'sad' 'said' 'sake' 'same' 'satified'\n",
      " 'satisfying' 'saturday' 'saw' 'say' 'saying' 'says' 'scale' 'scary'\n",
      " 'scenery' 'scenes' 'school' 'sciorra' 'screen' 'screw' 'script'\n",
      " 'scripted' 'season' 'seasons' 'see' 'seeing' 'seem' 'seemed' 'seems'\n",
      " 'seen' 'sense' 'sensitively' 'series' 'sesons' 'sets' 'setting' 'settled'\n",
      " 'several' 'severe' 'shape' 'she' 'sheesh' 'should' 'show' 'shows' 'side'\n",
      " 'similar' 'simple' 'since' 'sit' 'skit' 'slinging' 'slow' 'small' 'smile'\n",
      " 'so' 'socially' 'solely' 'some' 'someone' 'somewhat' 'somewhere' 'son'\n",
      " 'sorry' 'sort' 'sound' 'spectacular' 'spectrum' 'stand' 'star' 'starred'\n",
      " 'stars' 'start' 'starting' 'starts' 'stated' 'stay' 'steve' 'still'\n",
      " 'stop' 'stories' 'story' 'storyline' 'strengths' 'struggles' 'such'\n",
      " 'sundance' 'sunshine' 'super' 'superb' 'supplemental' 'sure' 'sweet'\n",
      " 'sympathies' 'take' 'talked' 'talking' 'targets' 'taylor' 'tears'\n",
      " 'technique' 'telling' 'terrible' 'than' 'thank' 'thanks' 'that' 'the'\n",
      " 'theater' 'their' 'them' 'then' 'there' 'these' 'they' 'thing' 'things'\n",
      " 'think' 'thinking' 'this' 'those' 'though' 'thought' 'three' 'through'\n",
      " 'throughout' 'thumbs' 'tie' 'till' 'time' 'timely' 'times' 'tire' 'tired'\n",
      " 'tis' 'to' 'together' 'token' 'told' 'tolerable' 'tom' 'ton' 'too' 'took'\n",
      " 'totally' 'town' 'track' 'tragic' 'traumatized' 'triangle' 'tried'\n",
      " 'triumph' 'trouble' 'true' 'trying' 'tv' 'type' 'unbearable'\n",
      " 'unbelievable' 'underlying' 'underrated' 'understand' 'understanding'\n",
      " 'unenjoyable' 'unique' 'unlikeable' 'unpleasant' 'unsatisfying' 'up' 'us'\n",
      " 'use' 'using' 'usually' 'values' 've' 'version' 'very' 'victim' 'video'\n",
      " 'visual' 'voice' 'volumes' 'wait' 'waiting' 'walk' 'want' 'wanted' 'war'\n",
      " 'warping' 'was' 'wasn' 'waste' 'wasted' 'watch' 'watched' 'watching'\n",
      " 'way' 'we' 'wears' 'weave' 'weaver' 'week' 'weekend' 'weeks' 'weird'\n",
      " 'well' 'were' 'what' 'when' 'where' 'which' 'while' 'who' 'whole' 'whom'\n",
      " 'wig' 'will' 'willis' 'winning' 'wish' 'wished' 'with' 'within' 'witty'\n",
      " 'woke' 'won' 'wonder' 'wonderful' 'wondering' 'woodlawn' 'words'\n",
      " 'working' 'workout' 'workouts' 'works' 'workshop' 'worth' 'would'\n",
      " 'wouldn' 'wounds' 'wracking' 'write' 'writing' 'written' 'year' 'yelling'\n",
      " 'yet' 'you' 'young' 'younger' 'your' 'youth']\n"
     ]
    }
   ],
   "source": [
    "encoded, feature_names = encode(text_data, method='tfidf')\n",
    "print(encoded, '\\n', feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 111)\t0.9425837889433633\n",
      "  (1, 0)\t0.3339697603394254\n",
      "  (2, 1024)\t0.10886151347263386\n",
      "  (2, 1013)\t0.10886151347263386\n",
      "  (2, 1002)\t0.08859549636167348\n",
      "  (2, 991)\t0.04896634068110703\n",
      "  (2, 980)\t0.09353086334927205\n",
      "  (2, 969)\t0.09353086334927205\n",
      "  (2, 958)\t0.10886151347263386\n",
      "  (2, 947)\t0.07820021322591024\n",
      "  (2, 936)\t0.10886151347263386\n",
      "  (2, 925)\t0.10886151347263386\n",
      "  (2, 914)\t0.08115358751383288\n",
      "  (2, 903)\t0.10886151347263386\n",
      "  (2, 892)\t0.10886151347263386\n",
      "  (2, 881)\t0.09353086334927205\n",
      "  (2, 870)\t0.09989365803879104\n",
      "  (2, 859)\t0.10886151347263386\n",
      "  (2, 848)\t0.07326484623831167\n",
      "  (2, 837)\t0.10886151347263386\n",
      "  (2, 826)\t0.10886151347263386\n",
      "  (2, 815)\t0.08200799432985624\n",
      "  (2, 804)\t0.06582293739047107\n",
      "  (2, 793)\t0.09989365803879104\n",
      "  (2, 782)\t0.0755951524815864\n",
      "  :\t:\n",
      "  (99, 929)\t0.13308951797479568\n",
      "  (99, 523)\t0.1230754314483612\n",
      "  (99, 504)\t0.15721766674167728\n",
      "  (99, 428)\t0.10359545178128121\n",
      "  (99, 396)\t0.12772360054816284\n",
      "  (99, 344)\t0.10896136920791404\n",
      "  (99, 323)\t0.07946730301439958\n",
      "  (99, 317)\t0.13308951797479568\n",
      "  (99, 222)\t0.22398039401134254\n",
      "  (99, 34)\t0.24575172638746345\n",
      "  (99, 1090)\t0.1230754314483612\n",
      "  (99, 1068)\t0.11530790248268014\n",
      "  (99, 1057)\t0.10617511772682028\n",
      "  (99, 991)\t0.23119707442605403\n",
      "  (99, 848)\t0.11530790248268014\n",
      "  (99, 815)\t0.12906830899813485\n",
      "  (99, 738)\t0.17572409647757928\n",
      "  (99, 705)\t0.10359545178128121\n",
      "  (99, 683)\t0.0759242921516555\n",
      "  (99, 672)\t0.06619206595527609\n",
      "  (99, 661)\t0.19789456536295913\n",
      "  (99, 606)\t0.15721766674167728\n",
      "  (99, 364)\t0.06373389947190801\n",
      "  (99, 309)\t0.07270881746933561\n",
      "  (99, 0)\t0.12141014334830158 \n",
      " ['10' '100' '1000' ... '997' '998' '999']\n"
     ]
    }
   ],
   "source": [
    "encoded, feature_names = encode(processed_tokens, method='tfidf')\n",
    "print(encoded, '\\n', feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding for wonder:\n",
      " [-0.2682781   0.05656989 -0.24797943 -0.37317818  0.2778695  -0.46968704\n",
      "  0.05414895  0.3541814   0.04163877 -0.39789274 -0.48068455 -0.33329538\n",
      " -0.10688213  0.1490041   0.23736641 -0.04677843 -0.1049867  -0.15110363\n",
      " -0.63354564 -0.5101781  -0.21992087  0.16236828 -0.30687767 -0.73253125\n",
      " -0.1027553   0.18832017 -0.15864213 -0.43566254 -0.27945444  0.13407333\n",
      "  0.44579896  0.07903901 -0.12663959  0.12217898  0.19222319  0.7648557\n",
      "  0.05564063 -0.11666182  0.24248631 -0.15704098 -0.03921103 -0.17637302\n",
      " -0.1900275  -0.25876853  0.7257035  -0.10659317 -0.42954487  0.1401092\n",
      "  0.43662208 -0.32747096  0.25003207 -0.04918035  0.2782437   0.27853683\n",
      "  0.1721012   0.36672452  0.27644622  0.06565977  0.27892622  0.5040151\n",
      "  0.24384251 -0.06523824 -0.0947395   0.03707081 -0.33635426 -0.14368303\n",
      " -0.13097407 -0.19247366 -0.30029452  0.5511172  -0.51381344 -0.22787963\n",
      "  0.16376664  0.18174072  0.37627915  0.03374196 -0.06209064  0.08206993\n",
      " -0.25402302  0.40802222 -0.03640985  0.26627225 -0.14359748  0.21307777\n",
      " -0.12021955 -0.23892796 -0.3177994   0.41655922  0.482492   -0.0304824\n",
      "  0.4877242   0.25842577  0.01101981 -0.11526466  0.5223892   0.11475798\n",
      "  0.328941   -0.52496296  0.34464636  0.01318115]\n",
      "Similar words to wonder:\n",
      " [('truth', 0.8829271793365479), ('write', 0.8812893033027649), ('preach', 0.8777831792831421), ('die', 0.8745735883712769), ('confidence', 0.8743586540222168)]\n"
     ]
    }
   ],
   "source": [
    "text_data = df['text'].iloc[:5000]\n",
    "\n",
    "model = encode(text_data, method='word2vec')\n",
    "print(f\"Encoding for wonder:\\n\", model.wv['wonder'])\n",
    "similar_words = model.wv.most_similar('wonder', topn=5)\n",
    "print(f\"Similar words to wonder:\\n\", similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding for wonder:\n",
      " [ 0.16086692  0.30598474 -0.17497046 -0.20681019  0.2925442  -0.64241797\n",
      "  0.44970492  0.6764204  -0.16334963 -0.52434754 -0.30554605 -0.5019915\n",
      "  0.34917587  0.02098608  0.28995657 -0.31806248  0.11464727 -0.43861538\n",
      " -0.04815066 -0.7191057   0.17865695  0.00530987 -0.13059686 -0.31731272\n",
      " -0.03845894 -0.07759701 -0.334159   -0.3255919  -0.10026959  0.08671506\n",
      " -0.02669155  0.21938714 -0.10444628 -0.02559016 -0.43327513  0.59971434\n",
      " -0.1710534  -0.27486742 -0.04487635 -0.60378796  0.4245313  -0.16068615\n",
      "  0.35787144  0.16793169  0.24154028 -0.0855519  -0.2070801  -0.270541\n",
      " -0.0449572   0.17332053  0.14195317 -0.24066351 -0.24884634 -0.12448142\n",
      " -0.12402733 -0.06964699  0.2039691   0.34167814 -0.04012671  0.1758891\n",
      "  0.14964083 -0.04900362  0.07123719 -0.04504792 -0.08571136  0.44717497\n",
      "  0.11712946  0.04788008 -0.5379231   0.24338299 -0.43478352  0.4496781\n",
      "  0.27436784 -0.16529989  0.23626308  0.01201144  0.01900251 -0.00990616\n",
      " -0.35267198  0.05730054 -0.17312539  0.02401786 -0.7439224   0.539654\n",
      " -0.00460697  0.17944412  0.13720842 -0.02599035  0.3480322  -0.02473109\n",
      "  0.41020995  0.5353966  -0.25442612  0.34313136  0.71005106  0.01895928\n",
      "  0.04460594 -0.3068561   0.01049529 -0.21670805]\n",
      "Similar words to wonder:\n",
      " [('wondering', 0.9533655047416687), ('you,', 0.947097897529602), ('anything,', 0.9433168172836304), ('guessing', 0.9424496293067932), ('on.', 0.942267894744873)]\n"
     ]
    }
   ],
   "source": [
    "vocabulary, processed_tokens = preprocess(text_data)\n",
    "\n",
    "model = encode(processed_tokens, method='word2vec')\n",
    "\n",
    "\n",
    "def create_reverse_vocab(vocabulary):\n",
    "    return {idx: word for word, idx in vocabulary.items()}\n",
    "\n",
    "rev_vocab = create_reverse_vocab(vocabulary)\n",
    "\n",
    "index_to_check = 748\n",
    "word_to_check = rev_vocab[index_to_check]\n",
    "\n",
    "print(f\"Encoding for {word_to_check}:\\n\", model.wv[str(index_to_check)])\n",
    "similar_indices = model.wv.most_similar(str(index_to_check), topn=5)\n",
    "similar_words = [(rev_vocab[int(idx)], similarity) for idx, similarity in similar_indices]\n",
    "print(f\"Similar words to {word_to_check}:\\n\", similar_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
