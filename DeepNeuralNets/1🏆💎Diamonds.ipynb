{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3pqxgX4DxeH"
      },
      "source": [
        "<small><font color=gray>Notebook author: <a href=\"https://www.linkedin.com/in/olegmelnikov/\" target=\"_blank\">Oleg Melnikov</a> ©2021 onwards</font></small><hr style=\"margin:0;background-color:silver\">\n",
        "\n",
        "**<font size=6>💎Diamonds</font>**. [**Instructions**](https://colab.research.google.com/drive/1riOGrE_Fv-yfIbM5V4pgJx4DWcd92cZr#scrollTo=ITaPDPIQEgXV) for running Colabs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOLsFW8RMbgp"
      },
      "source": [
        "<small>**(Optional) CONSENT.** <mark>[ X ]</mark> We consent to sharing our Colab (after the assignment ends) with other students/instructors for educational purposes. We understand that sharing is optional and this decision will not affect our grade in any way. <font color=gray><i>(If ok with sharing your Colab for educational purposes, leave \"X\" in the check box.)</i></font></small>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPXkUBs6eMHH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d479347-9dee-4de7-8a9d-47f7807366d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive; drive.mount('/content/drive')   # OK to enable, if your kaggle.json file is stored in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8XoC8VqBXGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54800cd9-4c38-43a4-b2d2-62855aa9b98d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "- competition is now set to: 21jan25-diamonds\n",
            "Using competition: 21jan25-diamonds\n",
            "  teamId  teamName                       submissionDate       score            \n",
            "--------  -----------------------------  -------------------  ---------------  \n",
            "13244663  1 Oluwatobi_Daniel_David       2025-02-02 19:23:21  575.1743229999   \n",
            "13256813  12_Nainika_Arvin_Jenelle       2025-02-02 02:17:51  596.7469104999   \n",
            "13271090  💎5 Sichao Liu and Yang Zhang   2025-02-03 00:08:33  611.5747210000   \n",
            "13244737  💎 10                           2025-02-02 01:35:57  621.1262089999   \n",
            "13256842  3 Shuai & Casimir              2025-02-03 02:19:07  629.7049565000   \n",
            "13275591  2 Kumar Ray Josh               2025-02-03 00:05:07  633.0236220000   \n",
            "13203520  💎 4_JacobMarx_ChipHenderson    2025-02-03 01:19:08  638.3123025000   \n",
            "13244767  Team-9 💎                       2025-02-03 01:44:58  663.4061924716   \n",
            "13240845  7_Austin_Madihah               2025-02-02 22:15:39  671.8027539999   \n",
            "13265250  11.Shunguan&JungWooJamesJeong  2025-02-03 02:19:26  679.4166254999   \n",
            "13253259  6_ShaileshJoshYuliia           2025-02-03 01:47:41  703.8261595000   \n",
            "13240536  8 Simmons Willis Venero        2025-02-02 14:54:56  730.5352555000   \n",
            "13199316  💎Baseline 🐍                    2025-01-09 03:25:40  1087.5854735000  \n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle > log  # upgrade kaggle package (to avoid a warning)\n",
        "!mkdir -p ~/.kaggle                                           # .kaggle folder must contain kaggle.json for kaggle executable to properly authenticate you to Kaggle.com\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json >log  # First, download kaggle.json from kaggle.com (in Account page) and place it in the root of mounted Google Drive\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json > log                   # Alternative location of kaggle.json (without a connection to Google Drive)\n",
        "!chmod 600 ~/.kaggle/kaggle.json                              # give only the owner full read/write access to kaggle.json\n",
        "!kaggle config set -n competition -v 21jan25-diamonds         # set the competition context for the next few kaggle API calls. !kaggle config view - shows current settings\n",
        "!kaggle competitions download >> log                          # download competition dataset as a zip file\n",
        "!unzip -o *.zip >> log                                        # Kaggle dataset is copied as a single file and needs to be unzipped.\n",
        "!kaggle competitions leaderboard --show                       # print public leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CyC-JlZFga1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b4c95ed-f065-4a20-b623-d4259d36538e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 386 ms, sys: 829 µs, total: 387 ms\n",
            "Wall time: 417 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "%%capture\n",
        "%reset -f\n",
        "from IPython.core.interactiveshell import InteractiveShell as IS; IS.ast_node_interactivity = \"all\"\n",
        "import numpy as np, pandas as pd, time, matplotlib.pyplot as plt, seaborn as sns, os, tqdm, re, sys, cv2, skimage\n",
        "ToCSV = lambda df, fname: df.round(2).to_csv(f'{fname}.csv', index_label='id') # rounds values to 2 decimals\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'; os.environ['TF_CUDNN_DETERMINISTIC'] = '1'; # allows seeding RNG on GPU\n",
        "\n",
        "class Timer():\n",
        "  def __init__(self, lim:'RunTimeLimit'=60): self.t0, self.lim, _ = time.time(), lim, print(f'⏳ started. You have {lim} sec. Good luck!')\n",
        "  def ShowTime(self):\n",
        "    msg = f'Runtime is {time.time()-self.t0:.0f} sec'\n",
        "    print(f'\\033[91m\\033[1m' + msg + f' > {self.lim} sec limit!!!\\033[0m' if (time.time()-self.t0-1) > self.lim else msg)\n",
        "\n",
        "np.set_printoptions(linewidth=100, precision=2, edgeitems=2, suppress=True)\n",
        "pd.set_option('display.max_columns', 20, 'display.precision', 2, 'display.max_rows', 4)\n",
        "tDIR, sDIR = 'trainXY/', 'testY/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X00bQLb5FpxU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "de4bccd1-440c-4fdf-aff5-4fe4839ae77c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        carat  depth  table     x     y     z cut color clarity   price\n",
              "0        0.35   67.2   57.1  4.64  4.69  2.87   I     G     VS1     NaN\n",
              "1        1.64   67.3   60.7  7.84  7.82  4.94   V     E     SI1     NaN\n",
              "...       ...    ...    ...   ...   ...   ...  ..   ...     ...     ...\n",
              "199998   0.48   68.7   53.0  4.47  4.45  2.72   I     G      IF  1474.0\n",
              "199999   0.48   65.0   64.7  5.60  5.62  3.44   I     H     VS2   765.0\n",
              "\n",
              "[200000 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e4035b5-5e19-43ad-883d-8bc09f5b2e69\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>carat</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "      <th>cut</th>\n",
              "      <th>color</th>\n",
              "      <th>clarity</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.35</td>\n",
              "      <td>67.2</td>\n",
              "      <td>57.1</td>\n",
              "      <td>4.64</td>\n",
              "      <td>4.69</td>\n",
              "      <td>2.87</td>\n",
              "      <td>I</td>\n",
              "      <td>G</td>\n",
              "      <td>VS1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.64</td>\n",
              "      <td>67.3</td>\n",
              "      <td>60.7</td>\n",
              "      <td>7.84</td>\n",
              "      <td>7.82</td>\n",
              "      <td>4.94</td>\n",
              "      <td>V</td>\n",
              "      <td>E</td>\n",
              "      <td>SI1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>0.48</td>\n",
              "      <td>68.7</td>\n",
              "      <td>53.0</td>\n",
              "      <td>4.47</td>\n",
              "      <td>4.45</td>\n",
              "      <td>2.72</td>\n",
              "      <td>I</td>\n",
              "      <td>G</td>\n",
              "      <td>IF</td>\n",
              "      <td>1474.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>0.48</td>\n",
              "      <td>65.0</td>\n",
              "      <td>64.7</td>\n",
              "      <td>5.60</td>\n",
              "      <td>5.62</td>\n",
              "      <td>3.44</td>\n",
              "      <td>I</td>\n",
              "      <td>H</td>\n",
              "      <td>VS2</td>\n",
              "      <td>765.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e4035b5-5e19-43ad-883d-8bc09f5b2e69')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0e4035b5-5e19-43ad-883d-8bc09f5b2e69 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0e4035b5-5e19-43ad-883d-8bc09f5b2e69');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a13f2b42-26a7-4daa-b3df-a5e5788a29eb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a13f2b42-26a7-4daa-b3df-a5e5788a29eb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a13f2b42-26a7-4daa-b3df-a5e5788a29eb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c42c8c07-5115-4502-8eee-a9c276d80974\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c42c8c07-5115-4502-8eee-a9c276d80974 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "df = pd.read_csv('XY_diamonds.csv'); df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh1X0Ck_v-RM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b29694a8-ce06-4a5a-e627-5b5d99163bd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 200000 entries, 0 to 199999\n",
            "Series name: price\n",
            "Non-Null Count   Dtype  \n",
            "--------------   -----  \n",
            "160000 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 1.5 MB\n"
          ]
        }
      ],
      "source": [
        "df.price.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7OuVizOFsFF"
      },
      "outputs": [],
      "source": [
        "vX = df.query('price!=price').drop('price', axis=1)  # slice a test sample, price!=price is True for NaN values\n",
        "tXY = df.query('price==price')                       # slice a training sample, price==price is True for non-NaN values\n",
        "tX, tY = tXY.drop('price', axis=1), tXY.price        # split into training I/O"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4gelET6Hb2A"
      },
      "outputs": [],
      "source": [
        "def ScatterCorrHist(df):\n",
        "  def corrdot(*args, **kwargs):\n",
        "    # credit: https://stackoverflow.com/questions/48139899\n",
        "    corr_r = args[0].corr(args[1], 'pearson')\n",
        "    corr_text = f\"{corr_r:2.2f}\".replace(\"0.\", \".\")\n",
        "    ax = plt.gca();\n",
        "    ax.set_axis_off();\n",
        "    msz = abs(corr_r) * 5000   # marker size\n",
        "    fsz = abs(corr_r) * 40 + 5 # font size\n",
        "    ax.scatter([.5], [.5], msz, [corr_r], alpha=0.5, cmap='coolwarm', vmin=-1, vmax=1, transform=ax.transAxes)\n",
        "    ax.annotate(corr_text, [.5, .5,],  xycoords=\"axes fraction\", ha='center', va='center', fontsize=fsz)\n",
        "\n",
        "  sns.set(style='white', font_scale=.8);\n",
        "  g = sns.PairGrid(df, aspect=1, diag_sharey=False);\n",
        "  g.fig.set_size_inches(20,10)\n",
        "  g.map_lower(sns.regplot, lowess=True, ci=False, line_kws={'color':'red'}, scatter_kws={'s':1});\n",
        "  g.map_diag(sns.histplot, kde_kws={'color':'black'});\n",
        "  g.map_upper(corrdot);\n",
        "  g.fig.suptitle(\"Scatter plot, Correlations and histograms on diagonal\", y=1);\n",
        "  _ = plt.subplots_adjust(hspace=0.02, wspace=0.02);\n",
        "  _ = plt.show();\n",
        "\n",
        "# ScatterCorrHist(tXY.head(200))  # takes a minute time to run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4_C58bbHuja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "825093c2-91b6-4fbd-e552-43c4bb9a39b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ started. You have 60 sec. Good luck!\n"
          ]
        }
      ],
      "source": [
        "tmr = Timer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NcTKbw3KhAn"
      },
      "source": [
        "<hr color=green size=40>\n",
        "\n",
        "<strong><font color=green size=5>⏳Timed Green Playground (TGP): Your ideas, code, documentation, and timer START HERE!</font></strong>\n",
        "\n",
        "<font color=green>Students: Keep all your definitions, code, documentation in <b>TGP</b>. Modifying any code outside of TGP incurs penalties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJs0jS4fIO1j"
      },
      "source": [
        "<font color=green><h3><b>$\\alpha$. Build polynomial features</b><h3>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting data\n",
        "\n",
        "We split our data taking care to ensure that we had a representative sample from the long tail of less-likely values that we can see in the distribution of training prices from below:\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1v6Ele7a_JWjb8e5XPDlb08_75is7QiJH'>\n",
        "\n",
        "By stratifying our samples in our train/test split, we achieved a better MAE, [see our writeup](#scrollTo=39zfwMOXwHAD).\n"
      ],
      "metadata": {
        "id": "YR3IBcKevJrN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-RL43wuSCrZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import  KBinsDiscretizer\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# We have a continuous dependent variable and want to do stratified k-fold sampling so we can hopefully\n",
        "# attend to the long tail of prices\n",
        "# https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization.html\n",
        "binning_transformer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
        "price_binned = binning_transformer.fit_transform(tY.values.reshape(-1, 1)).flatten()\n",
        "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "\n",
        "for train_index, test_index in stratified_split.split(tX, price_binned):\n",
        "    X_train, X_test = tX.iloc[train_index], tX.iloc[test_index]\n",
        "    y_train, y_test = tY.iloc[train_index], tY.iloc[test_index]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Engineering features\n",
        "\n",
        "In order to capture potential nonlinearities between the different features, we decided to poke around and try some different combined features through trial and error. More information can be found in [our ideas writeup](#scrollTo=39zfwMOXwHAD)."
      ],
      "metadata": {
        "id": "14ftHpKZ5gM4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDO-jQElsK_0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "def create_engineered_features(X: pd.DataFrame):\n",
        "    X = X.copy()  # Avoid modifying the original data\n",
        "\n",
        "    # Create new features\n",
        "    X['volume'] = X['x'] * X['y'] * X['z']\n",
        "    X['carat_volume'] = X['carat'] * X['volume']\n",
        "\n",
        "    # Ratios\n",
        "    X['table_to_carat_ratio'] = X['table'] / X['carat']\n",
        "    X['depth_to_carat_ratio'] = X['depth'] / X['carat']\n",
        "\n",
        "    return X\n",
        "\n",
        "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = create_engineered_features(X)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clipping predictions\n",
        "\n",
        "We noticed that the distribution of prices in the training and test sets start at a certain non-zero value, and end at a certain value. However, our initial models were predicting values that were not represented in the train/test sets, so we thought a naive (but effective) thing to do would be to clip values.\n",
        "\n",
        "We ended up just clipping values between the lowest and highest price present in the training set.\n",
        "\n",
        "Through this, we discovered that the regressor is an estimator (which is different than a transformer) and therefore doesn't need to return itself—hence the need to create a custom regressor (that contains the estimator that we want) instead of tacking on some sort of clipping transformer to the end of our pipeline."
      ],
      "metadata": {
        "id": "sSB2C-jx5xGa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zg0BUluhv4tE"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "@dataclass\n",
        "class ClippingRegressor(BaseEstimator, RegressorMixin):\n",
        "    \"\"\"Regressor that clips predictions between a min_val and max_val.\"\"\"\n",
        "    base_estimator: BaseEstimator\n",
        "    min_val: float = 0.0\n",
        "    max_val: float = 1.0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.base_estimator.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.clip(self.base_estimator.predict(X), self.min_val, self.max_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions\n",
        "\n",
        "We thought it was nice to have a way to print out not only the mean score and standard deviation of the best parameters found via grid search, but also of all the others."
      ],
      "metadata": {
        "id": "jzlrI15M6gc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions below\n",
        "\n",
        "def _print_grid_search(grid_search):\n",
        "    \"\"\"Prints grid search results: best score, best params, and all scores.\"\"\"\n",
        "    idx = grid_search.best_index_\n",
        "    score, std, params = (\n",
        "        # Note: score inverted since it reports a negative value\n",
        "        -grid_search.cv_results_[\"mean_test_score\"][idx],\n",
        "        grid_search.cv_results_[\"std_test_score\"][idx], grid_search.cv_results_[\"params\"][idx])\n",
        "\n",
        "    print(f\"Best Score: {score:.4f} ± {std:.4f}\")\n",
        "    print(f\"Best Params: {params}\")\n",
        "    print(\"-----------\")\n",
        "\n",
        "    # Invert score since it reports a negative value\n",
        "    means = -grid_search.cv_results_[\"mean_test_score\"]\n",
        "    stds = grid_search.cv_results_[\"std_test_score\"]\n",
        "    params = grid_search.cv_results_[\"params\"]\n",
        "\n",
        "    for mean, std, param in zip(means, stds, params):\n",
        "        print(f\"Score: {mean:.4f} ± {std:.4f}, Params: {params}\")"
      ],
      "metadata": {
        "id": "0-8xJbdJzAvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YACmBWMZxViZ"
      },
      "source": [
        "<font color=green><h3><b>$\\beta$. Fit the model to the training dataset</b><h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model pipeline\n",
        "\n",
        "The model pipeline is defined below, steps comprising of:\n",
        "\n",
        "1. Feature engineering: generating new features from our existing ones\n",
        "2. Preprocessing: encoding the categorical variables either with ordinal or one-hot encoding\n",
        "3. Polynomial: Creating polynomial features from our numerical features\n",
        "4. Transforming: transforming our dependent variable using `log` and `exp` [3, pp. 75-78][4]\n",
        "4. Regression: Using one of many different regression estimators (e.g., `Ridge`)\n",
        "5. Clipping (clipping our output as described above)"
      ],
      "metadata": {
        "id": "KOi9amxx6z5Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjkQvaYMN3J6"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer, make_column_selector, TransformedTargetRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import (\n",
        "    FunctionTransformer, OrdinalEncoder, OneHotEncoder, PolynomialFeatures, MinMaxScaler, KBinsDiscretizer, StandardScaler,\n",
        ")\n",
        "from sklearn.linear_model import (\n",
        "    LinearRegression, Ridge, RidgeCV,\n",
        "    BayesianRidge, ElasticNetCV, LarsCV, LassoLarsCV, OrthogonalMatchingPursuitCV,\n",
        ")\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# NOTE: Going off of https://www.brilliantearth.com/diamond/buying-guide/cut/ (which may be an assumption)\n",
        "cut_categories = [\"P\", \"F\", \"G\", \"V\", \"I\"]\n",
        "# NOTE: Going off of https://4cs.gia.edu/en-us/blog/diamond-color-chart-official-gia-color-scale/ (which may be an assumption)\n",
        "color_categories = [\"J\", \"I\", \"H\", \"G\", \"F\", \"E\", \"D\"]\n",
        "# NOTE: Going off of https://4cs.gia.edu/en-us/diamond-clarity/ (which may be an assumption)\n",
        "clarity_categories = [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]\n",
        "\n",
        "categorical_features = [\"cut\", \"color\", \"clarity\"]\n",
        "\n",
        "ordinal_preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"ordinal\", OrdinalEncoder(categories=[\n",
        "            cut_categories,\n",
        "            color_categories,\n",
        "            clarity_categories\n",
        "        ]), categorical_features),\n",
        "        (\"num\", StandardScaler(), make_column_selector(dtype_include='number')),\n",
        "    ],\n",
        "    remainder=\"passthrough\"\n",
        ")\n",
        "\n",
        "onehot_preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
        "        (\"num\", StandardScaler(), make_column_selector(dtype_include='number')),\n",
        "    ],\n",
        "    remainder=\"passthrough\"\n",
        ")\n",
        "\n",
        "log_transformer = FunctionTransformer(np.log, inverse_func=np.exp)\n",
        "\n",
        "model_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"feature_engineering\", FeatureEngineering()),\n",
        "        (\"preprocessor\", onehot_preprocessor),\n",
        "        (\"svd\", TruncatedSVD(n_components=23)),\n",
        "        (\"poly\", PolynomialFeatures(degree=3)),\n",
        "        (\"clipped_regressor\", ClippingRegressor(\n",
        "            base_estimator=TransformedTargetRegressor(\n",
        "                regressor=Ridge(alpha=0.0001),\n",
        "                transformer=log_transformer,\n",
        "            ),\n",
        "            min_val=y_train.min(),\n",
        "            max_val=y_train.max())),\n",
        "    ]\n",
        ")\n",
        "\n",
        "###############################\n",
        "# HYPERPARAMETER OPTIMIZATION #\n",
        "###############################\n",
        "# param_grid = [{\n",
        "#     \"feature_engineering\": [FeatureEngineering()],\n",
        "#     # Ordinal has way fewer features\n",
        "#     # TODO: If we use onehot, maybe we can PCA to dumb them down?\n",
        "#     \"preprocessor\": [ordinal_preprocessor],\n",
        "#     \"preprocessor__num\": [StandardScaler()],\n",
        "#     # \"clipped_regressor__base_estimator__alpha\": [1],\n",
        "#     \"clipped_regressor__base_estimator__regressor\": [Ridge()],\n",
        "#     \"clipped_regressor__base_estimator__regressor__alpha\": [0.005, 0.01, 0.1],\n",
        "# }]\n",
        "#\n",
        "# NOTE: Ensure that training cell below is commented out.\n",
        "# m = GridSearchCV(\n",
        "#     estimator=model_pipeline,\n",
        "#     param_grid=param_grid,\n",
        "#     cv=5,\n",
        "#     scoring=\"neg_mean_absolute_error\",\n",
        "#     n_jobs=-1,\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "# m.fit(X_train, y_train)\n",
        "\n",
        "# _print_grid_search(m)\n",
        "###############################\n",
        "# HYPERPARAMETER OPTIMIZATION #\n",
        "###############################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "VC1vzPpR8nVk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AjkdC1ZGhdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6224cc6-49e2-4fbe-a223-31850e04ed44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.21188e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
          ]
        }
      ],
      "source": [
        "m = model_pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73wJmtcJwaIL"
      },
      "source": [
        "<font color=green><h3><b>$\\gamma$. Generate and post-process predictions.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating metrics\n",
        "\n",
        "Generates MAE for both train and test sets."
      ],
      "metadata": {
        "id": "xuIRWLHT8pzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Predictions using the best model\n",
        "train_Y_pred_best = m.predict(X_train)\n",
        "test_Y_pred_best = m.predict(X_test)\n",
        "\n",
        "# Calculate MAE for train and test\n",
        "mae_train_best = mean_absolute_error(y_train, train_Y_pred_best)\n",
        "mae_test_best = mean_absolute_error(y_test, test_Y_pred_best)\n",
        "\n",
        "print(f\"Train MAE: {mae_train_best}\")\n",
        "print(f\"Test MAE: {mae_test_best}\")"
      ],
      "metadata": {
        "id": "Bp5FU3IXuhZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e012c7-f213-4f87-bf5e-67abb59d96fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train MAE: 558.152217662631\n",
            "Test MAE: 565.9691243334823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export\n",
        "\n",
        "Exports predictions from model `m`."
      ],
      "metadata": {
        "id": "uUm6KAPN8y58"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnRm96uR7HOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffd9e9d1-cfb5-41c1-aea9-0cd25a9f2088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "pY = pd.DataFrame(m.predict(vX), index=range(1,len(vX)+1), columns=['price'])  # ensure that labels and observations are in corresponding order\n",
        "pY = pY.clip(lower=10)  # ensures no negative prices\n",
        "\n",
        "# Uncomment to visualize distribution\n",
        "# _ = tY.hist(figsize=(40,3), bins=1000);  _ = plt.suptitle(\"Distribution of training prices\");\n",
        "# _ = pY.hist(figsize=(40,3), bins=1000);  _ = plt.suptitle(\"Distribution of predicted prices\");\n",
        "\n",
        "ToCSV(pY, 'TruncatedSVD23PolynominialDegree3Ridge0.0001')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HIV2gtQVOnGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMVDxm-kEJis"
      },
      "source": [
        "<font color=green><h3><b>$\\epsilon$. Idea Documentation (JHU students only)</b></h3>\n",
        "<details>\n",
        "  <summary>Instructions</summary>\n",
        "  <div>\n",
        "\n",
        "\n",
        "1. **Audience**. Your peers who will learn from your Colab and ideas therein.\n",
        "1. **Importance**. The ML/DL ideas are not entirely random, but are based on prior experience and systematized/organized experiments. We'd like students to share and learn from idea generation to idea experimentation process done in our class using tools learned thus far.\n",
        "1. **Format**. Keep it concise/precise in consistent font/presentation. Include numbers/IDs to your References, such as [1] or [[Géron22]](https://scholar.google.com/scholar?cluster=498861685923226475), where these are defined in your References section below. This helps link your ideas/experiments to external ideas.\n",
        "1. **Reproducibility**. Your description should contain reasonable details needed for reproducibility, i.e. describe the state of your modeling pipeline before the change is made, what is changed and how the idea was discovered, and what improvement it resulted in. Thus, peers can try this idea with an expectation of the value it brings. See examples below.\n",
        "1. **Bonus** points for the exceptional/exemplary/educational documentation (see grading rubric).\n",
        "****\n",
        "1. **TODO**: Describe the key idea in your work in the following format (similar to a \"micro publication\"):\n",
        "  1. **Title**. Give each idea a descriptive name (i.e. a micro abstract).\n",
        "    1. Ex(ample). <i>\"Thresholding carat feature outliers improves MAE by 3% on public LB\"</i>\n",
        "  1. **Idea Discovery**. What led you to this idea? Was it some [EDA](https://en.wikipedia.org/wiki/Exploratory_data_analysis), familiarity with this dataset or some of the features?\n",
        "    1. Ex. <i>\"We plotted all univariate distributions of variables and discovered that diamond carat had unreasonable (but rare) values below and above [0,10] interval, when plotted carat's histogram in the train and test sets, which contained 10 and 3 such outliers respectively. We decided to use 10 as a reasonable threshold because it is 99th percentile of carat values in the 20K baseline sample. See our histogram plot below [plot here]. \"</i>\n",
        "  1. **Finding's Importance**. Describe why you think the idea was important to proceed with.\n",
        "    1. Ex. <i>\"We use a linear model, the slope of which is sensitive to outliers on the periphery of the feature space domain. The fitted hyperplane slopes in the direction of the extreme training feature values thereby mapping a non-existent relation between carat size and diamond price, which is not expected to repeat in the test set. \"</i>\n",
        "  1. **Experiment Setup**.\n",
        "  How did you set up experiments to test your idea? What resources were helpful? What metric did you select, why and what values did you observe?\n",
        "    1. Ex. <i>\"To alleviate the impact of the outlying feature values, we need to either remove observations with extreme values, or somehow cap them (to stay within the distribution of the other carat values) or use a model insensitive to outliers (such as robust regression). We learned 3 suitable methods for treating outliers in [ref]: ... [It'd be great to briefly describe each method] We tried each one on a Baseline model, while keeping the competition-required [MAE](https://en.wikipedia.org/wiki/Mean_absolute_error) metric. We tested each method locally on the seeded 50/50 split of the 20K training set sampled in baseline Colab.\"</i>\n",
        "  1. **Results**. What was the result or metric improvement from implementing the experiment locally and/or on public LB?\n",
        "    1. Ex. <i>\"Baseline MAE was 539.1257546465 in public LB and 530 in local default experiment with 50/50 train-test split. When applied on the same-seed split, Methods 1,2,and 3 showed 1%, 2%, and 5% improvement on the test set. When uploaded to public LB, Method 3 showed a 3% improvement. So, we decided to keep method 3.\"</i>\n",
        "\n",
        "</div> </details>\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtOV3RVcwHAD"
      },
      "source": [
        "<font color=green><h4><b>Task 1. Preprocessing Ideas</b></h4>\n",
        "<details>\n",
        "  <summary>Instructions</summary>\n",
        "  <div>Explain a <b>key idea</b> that helped in <b>preprocessing pipeline</b>. This may be about some feature engineering, tricky subsampling, clustering, dimension reduction, etc. Use the format in TODO specified above. Remember to provide citation references for the peers to read more into your work.\n",
        "</div> </details>\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39zfwMOXwHAD"
      },
      "source": [
        "1. **Title**: Stratified Sampling and Feature Engineering Reduces MAE by 5%\n",
        "1. **Idea Discovery**:\n",
        "A random train-test split could lead to an imbalanced price distribution between the training and testing sets, as we [mentioned above](#scrollTo=YR3IBcKevJrN) (and we noticed the long tail distribution of the training price data). Hence, stratifying our samples might improve generalization. Additionally, as hinted [in the Starter Ideas section](#scrollTo=q4QO-u3t8xAO), we thought it'd be interesting to engineer some compound features to see what effect there might be on the final result.\n",
        "1. **Finding's Importance**:\n",
        "  1. *Stratified Sampling*: Viewing the distribution of the predicted prices versus the training prices led us to believe that if we did random sampling to generate our test and train sets, we may not have enough of the long tail in either set. So we looked around and found that `scikit-learn` has exactly what we needed to ensure we have enough data from each bin [1][2].\n",
        "  1. *Feature Engineering*: Being inspired by the starter ideas, we played around with different combinations of parameters that we thought might add some more information to our system (like a `table`-to-`carat` ratio).\n",
        "1. **Experiment Setup**:\n",
        "  1. *Train-test split*: We binned the train set (128,000) into five separate quantized bins using [`KBinsDiscretizer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html), and we held out the remaining 20% of available data (32,000) as a test set. We then used `StratifiedShuffleSplit`[1] to sample into our train and test buckets. This is opposed to sampling using [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split).\n",
        "  1. *Feature engineering*: We created a simple custom transformer (`FeatureEngineering`) to apply some different transformations, [such as `volume` and `table_to_carat_ratio`](#scrollTo=CDO-jQElsK_0).\n",
        "  1. *Hyperparameter optimization*: We used [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) along with the requested Mean Absolute Error (MAE) metric to determine which combination of the above changes might yield the best MAE.\n",
        "1. **Results**:\n",
        "  1. Our best MAE value was found with the following parameters:\n",
        "    1. *Feature Engineering*: Enabled\n",
        "    1. *Stratified sampling*: Enabled\n",
        "  1. Metrics\n",
        "    1. Previous MAE that we were able to find (Ridge regressor): 644.31\n",
        "    1. New MAE (training set): 609.50\n",
        "    1. New MAE (test set): 613.76\n",
        "  1. Therefore we were able to improve our MAE by 5% with our stratified sampling and feature engineering preprocessing (as measured with our local training and test sets; a commensurate change was noted on the public leaderboard)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppwkSmoEwHAD"
      },
      "source": [
        "<font color=green><h4><b>Task 2. Modeling Ideas</b></h4>\n",
        "<details>\n",
        "  <summary>Instructions</summary>\n",
        "  <div>Explain a <b>key idea</b> that helped with <b>model selection</b> in the format specified above. This may include tuning model parameters (perhaps a grid search with specific parameter range) or some other experiments, search/choice of the suitable model, experiments with postprocessing of model predictions, etc. Use the format in TODO specified above. Remember to provide citation references for the peers to read more into your work.\n",
        "</div> </details>\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBXlrkB9wHAD"
      },
      "source": [
        "1. **Title**: Clipping Predictions\n",
        "1. **Idea Discovery**: While exploring the dataset, we noticed that the price distribution in both the training and testing sets had non-zero values and capped at a certain maximum. However, our model was producing predictions outside the range of these values. To address this, we decided to clip the predicted values to ensure they fall within the range of the observed values in the dataset.\n",
        "1. **Finding's Importance**: Since the performance of our model is evaluated based on the MAE of its predicted values, clipping any predictions that fall outside the expected range is a logical step. This adjustment helps minimize the gap between the predicted and actual values, improving overall accuracy.\n",
        "1. **Experiment Setup**:\n",
        "  1. We first ran the model without any clipping and reviewed the predictions. Next, we applied clipping to the output to assess the impact on performance.\n",
        "  2. *Clipping Regressor*: As the regressor functions as an estimator, [mentioned above](#scrollTo=sSB2C-jx5xGa), we created a custom regressor incorporate clipping into the prediction process, ensuring that any values outside the desired range were clipped appropriately.\n",
        "  3. We utilized the Mean Absolute Error (MAE) metric to determine the clipped models performance vs the unclipped performance.\n",
        "1. **Results**:\n",
        "  1. Metrics\n",
        "    1. Previous MAE: 553.312\n",
        "    2. New MAE: 552.627"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Title**: Optimizing Model Hyperparameters with GridSearchCV\n",
        "1. **Idea Discovery**: While working on model training, we wanted to explore how different combinations of hyperparameters would affect model performance. Given that hyperparameters, such as the regularization strength and preprocessing methods, play a significant role in model accuracy, we decided to use GridSearchCV to systematically search for the best combination. This approach would help us optimize the model’s configuration to improve performance, as we noticed performance variability when changing hyperparameters manually.\n",
        "1. **Finding's Importance**: Hyperparameter tuning is crucial in machine learning as it can significantly impact the model's ability to generalize. By using GridSearchCV, we were able to automate the process of testing various hyperparameter combinations, ensuring we identified the optimal setup.\n",
        "1. **Experiment Setup**:\n",
        "  1. We determined a range of potential values for each hyperparameter:\n",
        "    1. Preprocessors: [OneHot encoder, Ordinal encoder]\n",
        "    2. Scalar: [Standard Scaler, MinMax Scaler],\n",
        "    3. Polynomial Features Degree: [1, 2, 3, 4, 5]\n",
        "    4. Models: [Ridge, LinearRegression, Lasso, ElasticNet, HuberRegressor, BayesianRidge]\n",
        "    5. Regressor Model alpha: [0.001, 0.005, 0.01, 0.1]  \n",
        "  2. We than ran GridSearchCV to determine the best combinations of these parameters.\n",
        "1. **Results**:\n",
        "  1. Best Hyperparameters\n",
        "    1. Preprocessors: OneHot Encoder\n",
        "    2. Scalar: Standard Scaler,\n",
        "    3. Polynomial Features Degree: 3\n",
        "    4. Regressor Model: Ridge\n",
        "    3. Regressor Model alpha: 0.0001   \n",
        "  2. Metrics\n",
        "    1. Previous MAE: 646.494\n",
        "    2. New MAE: 568.595"
      ],
      "metadata": {
        "id": "sePHPR1TuEmf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzBsjCvS_kEw"
      },
      "source": [
        "<font color=green><h3><b>$\\zeta$. References</b></h3>\n",
        "<details>\n",
        "  <summary>Instructions</summary>\n",
        "  <div>\n",
        "\n",
        "1. Cite your sources to help your peers learn from these (and to avoid plagiarism).\n",
        "1. HOML textbook should be cited, since we used it in this week's learning.\n",
        "1. Use Google Scholar to draw [APA](https://en.wikipedia.org/wiki/American_Psychological_Association) citation format for books and publications.\n",
        "1. Cite [StackOverflow](https://stackoverflow.com/), YouTube videos, package docs, open-access textbooks/publicaitons and other meaningful internet resources that you used.\n",
        "1. We may reward exceptional and meaningful citations (not just a list of [SKL](https://scikit-learn.org/stable/)/[TF](https://www.tensorflow.org/) manual pages and a list of articles.) For example, if you used an idea from a publication, indicate it in TGP with a number that corresponds to its reference in References.\n",
        "\n",
        "</div> </details>\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kr8Q-9T_nAb"
      },
      "source": [
        "1. 3.1. Cross-validation: Evaluating estimator performance. (n.d.). Scikit-Learn. Retrieved February 1, 2025, from https://scikit-learn/stable/modules/cross_validation.html\n",
        "1. “Using KBinsDiscretizer to Discretize Continuous Features.”. Retrieved February 1, 2025, from https://scikit-learn/stable/auto_examples/preprocessing/plot_discretization.html\n",
        "1. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 3rd Edition. (n.d.). Retrieved February 1, 2025, from https://learning.oreilly.com/library/view/hands-on-machine-learning/9781098125967/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoF2GoB_QGw9"
      },
      "source": [
        "<font size=5>⌛</font> <strong><font color=green size=5>Do not exceed competition's runtime limit! Do not write code outside TGP</font></strong>\n",
        "<hr color=green size=40>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bD1sdgYbNWQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "243a36ff-4c00-4a17-a7d1-4246c6cb1372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91m\u001b[1mRuntime is 62 sec > 60 sec limit!!!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "tmr.ShowTime()    # measure Colab's runtime. Do not remove. Keep as the last cell in your notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4QO-u3t8xAO"
      },
      "source": [
        "<details>\n",
        "  <summary><font size=5><b>💡Starter Ideas</b></font></summary>\n",
        "  <div>\n",
        "  \n",
        "1. Tune model hyperparameters\n",
        "1. Try to linear and non-linear feature normalization: shift/scale, log, divide features by features (investigate scatterplot matrix)\n",
        "1. Try higher order feature interactions ($x_i^a$, $x_ix_j$, ...) to identify new key features or their linear combinations. With too many features you can use a smaller subsample or reduce dimensionality of feature space using [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html), [tSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html), or [UMAP](https://umap-learn.readthedocs.io/en/latest/).\n",
        "1. Do a thorough EDA and understand non-linear relation in I/O. Are any interactions more special than others (E.g. is diamond *volume* a better predictor?)\n",
        "1. If you note a shift in trend for any predictors, try building a model for each trend.\n",
        "1. Evaluate predictions and focus on poorly predicted \"groups\". Can they be identified and modeled separately?\n",
        "1. Do scatter plots show piecewise linear shape? Can a separate linear model be used on each support of approximately linear X-Y relation?\n",
        "1. How are categorical features treated by the SKLearn models? Is there a [better way](https://www.google.com/search?q=ways+to+encode+categorical+data) to encode these (perhaps, ordinal) features?\n",
        "  1. E.g. you could replace codes (or groups of codes) with their frequencies, which may capture the implied \"distance\" or rarity between category levels.\n",
        "  1. If encoding ordinal features with integers, should non-equidistant values be considered?\n",
        "1. Learn about [modeling price of a diamond](https://www.google.com/search?q=machine+learning+model+price+diamond).\n",
        "1. Try post-processing: shifting/scaling/transforming the distribution of predicted prices `pY` to match the distribution of training prices `tY`\n",
        "\n",
        "</div> </details>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}