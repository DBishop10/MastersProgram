{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting atproto\n",
      "  Downloading atproto-0.0.55-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: click<9,>=8.1.3 in e:\\anaconda\\lib\\site-packages (from atproto) (8.1.7)\n",
      "Requirement already satisfied: cryptography<44,>=41.0.7 in e:\\anaconda\\lib\\site-packages (from atproto) (42.0.5)\n",
      "Collecting dnspython<3,>=2.4.0 (from atproto)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.25.0 in e:\\anaconda\\lib\\site-packages (from atproto) (0.27.2)\n",
      "Collecting libipld<4,>=2.0.0 (from atproto)\n",
      "  Downloading libipld-3.0.0-cp312-none-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting pydantic<3,>=2.7 (from atproto)\n",
      "  Downloading pydantic-2.10.2-py3-none-any.whl.metadata (170 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8.0 in e:\\anaconda\\lib\\site-packages (from atproto) (4.12.2)\n",
      "Collecting websockets<14,>=12 (from atproto)\n",
      "  Downloading websockets-13.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from click<9,>=8.1.3->atproto) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in e:\\anaconda\\lib\\site-packages (from cryptography<44,>=41.0.7->atproto) (1.16.0)\n",
      "Requirement already satisfied: anyio in e:\\anaconda\\lib\\site-packages (from httpx<0.28.0,>=0.25.0->atproto) (4.6.0)\n",
      "Requirement already satisfied: certifi in e:\\anaconda\\lib\\site-packages (from httpx<0.28.0,>=0.25.0->atproto) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\anaconda\\lib\\site-packages (from httpx<0.28.0,>=0.25.0->atproto) (1.0.5)\n",
      "Requirement already satisfied: idna in e:\\anaconda\\lib\\site-packages (from httpx<0.28.0,>=0.25.0->atproto) (3.7)\n",
      "Requirement already satisfied: sniffio in e:\\anaconda\\lib\\site-packages (from httpx<0.28.0,>=0.25.0->atproto) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.25.0->atproto) (0.14.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2.7->atproto)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic<3,>=2.7->atproto)\n",
      "  Downloading pydantic_core-2.27.1-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: pycparser in e:\\anaconda\\lib\\site-packages (from cffi>=1.12->cryptography<44,>=41.0.7->atproto) (2.21)\n",
      "Downloading atproto-0.0.55-py3-none-any.whl (327 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading libipld-3.0.0-cp312-none-win_amd64.whl (192 kB)\n",
      "Downloading pydantic-2.10.2-py3-none-any.whl (456 kB)\n",
      "Downloading pydantic_core-2.27.1-cp312-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 27.8 MB/s eta 0:00:00\n",
      "Downloading websockets-13.1-cp312-cp312-win_amd64.whl (159 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: websockets, pydantic-core, libipld, dnspython, annotated-types, pydantic, atproto\n",
      "Successfully installed annotated-types-0.7.0 atproto-0.0.55 dnspython-2.7.0 libipld-3.0.0 pydantic-2.10.2 pydantic-core-2.27.1 websockets-13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install atproto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atproto import Client, client_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "profile = client.login('mehoha6465.bsky.social', 'idontcareaboutthisaccount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Betboom': ['Zorte', 'Magnojez', 'Nafay', 'S1ren', 'KaiRON-'],\n",
       " 'Cloud9': ['Ax1Le', 'Boombl4', 'HeavyGod', 'ICY', 'interz'],\n",
       " 'ECLOT': ['Dytor', 'nbqq', 'FORSYY', 'Blytz', 'kreaz'],\n",
       " 'FaZe Clan': ['rain', 'broky', 'karrigan', 'ropz', 'frozen'],\n",
       " 'Fnatic': ['KRIMZ', 'bodyy', 'matys', 'blameF', 'nawwk'],\n",
       " 'GamerLegion': ['Fl4mus', 'Zorte', 'Tauson', 'Sl3nd', 'Volt'],\n",
       " 'Natus Vincere': ['b1t', 'Aleksib', 'jL', 'iM', 'w0nderful'],\n",
       " 'Nemiga': ['Xant3r', '1eer', 'Riskyb0b', 'khaN', 'zweih'],\n",
       " 'Rebels': ['Innocent', 'Casey', 'Olimp', 'Flayy', 'Kisserek'],\n",
       " 'SAW': ['MUTiRiS', 'rmn', 'ewjerkz', 'story', 'Ag1l']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('initialTeamData.csv')\n",
    "\n",
    "# Convert to a dictionary where each team is a key and players are a list of values\n",
    "team_dict = df.groupby('team')['player'].apply(list).to_dict()\n",
    "\n",
    "team_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['Perfect World Shanghai Major 2024: European RMR A', 'Perfect World Shanghai Major 2024']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying for team: Betboom with tag: ['Perfect World Shanghai Major 2024: European RMR A', 'Perfect World Shanghai Major 2024']\n",
      "Querying for player: Zorte in team Betboom with tag: European RMR A\n",
      "Querying for player: Magnojez in team Betboom with tag: European RMR A\n",
      "Querying for player: Nafay in team Betboom with tag: European RMR A\n",
      "Querying for player: S1ren in team Betboom with tag: European RMR A\n",
      "Querying for player: KaiRON- in team Betboom with tag: European RMR A\n",
      "Tagged posts saved to tagged_posts_cs2.csv\n",
      "Querying for team: Cloud9 with tag: ['Perfect World Shanghai Major 2024: European RMR A', 'Perfect World Shanghai Major 2024']\n",
      "Querying for player: Ax1Le in team Cloud9 with tag: European RMR A\n",
      "Querying for player: Boombl4 in team Cloud9 with tag: European RMR A\n",
      "Querying for player: HeavyGod in team Cloud9 with tag: European RMR A\n",
      "Querying for player: ICY in team Cloud9 with tag: European RMR A\n",
      "Querying for player: interz in team Cloud9 with tag: European RMR A\n",
      "Tagged posts saved to tagged_posts_cs2.csv\n",
      "Querying for team: ECLOT with tag: ['Perfect World Shanghai Major 2024: European RMR A', 'Perfect World Shanghai Major 2024']\n",
      "Querying for player: Dytor in team ECLOT with tag: European RMR A\n",
      "Querying for player: nbqq in team ECLOT with tag: European RMR A\n",
      "Querying for player: FORSYY in team ECLOT with tag: European RMR A\n",
      "Querying for player: Blytz in team ECLOT with tag: European RMR A\n",
      "Querying for player: kreaz in team ECLOT with tag: European RMR A\n",
      "Tagged posts saved to tagged_posts_cs2.csv\n",
      "Querying for team: FaZe Clan with tag: ['Perfect World Shanghai Major 2024: European RMR A', 'Perfect World Shanghai Major 2024']\n",
      "Querying for player: rain in team FaZe Clan with tag: European RMR A\n",
      "Querying for player: broky in team FaZe Clan with tag: European RMR A\n",
      "Querying for player: karrigan in team FaZe Clan with tag: European RMR A\n",
      "Querying for player: ropz in team FaZe Clan with tag: European RMR A\n",
      "Querying for player: frozen in team FaZe Clan with tag: European RMR A\n",
      "Tagged posts saved to tagged_posts_cs2.csv\n",
      "Querying for team: Fnatic with tag: ['Perfect World Shanghai Major 2024: European RMR A', 'Perfect World Shanghai Major 2024']\n",
      "Querying for player: KRIMZ in team Fnatic with tag: European RMR A\n",
      "Querying for player: bodyy in team Fnatic with tag: European RMR A\n",
      "Querying for player: matys in team Fnatic with tag: European RMR A\n",
      "Querying for player: blameF in team Fnatic with tag: European RMR A\n",
      "Querying for player: nawwk in team Fnatic with tag: European RMR A\n",
      "Tagged posts saved to tagged_posts_cs2.csv\n",
      "Querying for team: GamerLegion with tag: ['Perfect World Shanghai Major 2024: European RMR A', 'Perfect World Shanghai Major 2024']\n",
      "Querying for player: Fl4mus in team GamerLegion with tag: European RMR A\n",
      "Querying for player: Zorte in team GamerLegion with tag: European RMR A\n",
      "Querying for player: Tauson in team GamerLegion with tag: European RMR A\n",
      "Querying for player: Sl3nd in team GamerLegion with tag: European RMR A\n",
      "Querying for player: Volt in team GamerLegion with tag: European RMR A\n",
      "Tagged posts saved to tagged_posts_cs2.csv\n",
      "Querying for team: Natus Vincere with tag: ['Perfect World Shanghai Major 2024: European RMR A', 'Perfect World Shanghai Major 2024']\n",
      "Querying for player: b1t in team Natus Vincere with tag: European RMR A\n",
      "Querying for player: Aleksib in team Natus Vincere with tag: European RMR A\n",
      "Querying for player: jL in team Natus Vincere with tag: European RMR A\n",
      "Querying for player: iM in team Natus Vincere with tag: European RMR A\n",
      "Querying for player: w0nderful in team Natus Vincere with tag: European RMR A\n",
      "Tagged posts saved to tagged_posts_cs2.csv\n",
      "Querying for team: Nemiga with tag: ['Perfect World Shanghai Major 2024: European RMR A', 'Perfect World Shanghai Major 2024']\n",
      "Querying for player: Xant3r in team Nemiga with tag: European RMR A\n",
      "Querying for player: 1eer in team Nemiga with tag: European RMR A\n",
      "Querying for player: Riskyb0b in team Nemiga with tag: European RMR A\n",
      "Querying for player: khaN in team Nemiga with tag: European RMR A\n",
      "Querying for player: zweih in team Nemiga with tag: European RMR A\n",
      "Tagged posts saved to tagged_posts_cs2.csv\n",
      "Querying for team: Rebels with tag: ['Perfect World Shanghai Major 2024: European RMR A', 'Perfect World Shanghai Major 2024']\n",
      "Querying for player: Innocent in team Rebels with tag: European RMR A\n",
      "Querying for player: Casey in team Rebels with tag: European RMR A\n",
      "Querying for player: Olimp in team Rebels with tag: European RMR A\n",
      "Querying for player: Flayy in team Rebels with tag: European RMR A\n",
      "Querying for player: Kisserek in team Rebels with tag: European RMR A\n",
      "Tagged posts saved to tagged_posts_cs2.csv\n",
      "Querying for team: SAW with tag: ['Perfect World Shanghai Major 2024: European RMR A', 'Perfect World Shanghai Major 2024']\n",
      "Querying for player: MUTiRiS in team SAW with tag: European RMR A\n",
      "Querying for player: rmn in team SAW with tag: European RMR A\n",
      "Querying for player: ewjerkz in team SAW with tag: European RMR A\n",
      "Querying for player: story in team SAW with tag: European RMR A\n",
      "Querying for player: Ag1l in team SAW with tag: European RMR A\n",
      "Tagged posts saved to tagged_posts_cs2.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from atproto_client import models\n",
    "import csv\n",
    "\n",
    "csv_data = []\n",
    "\n",
    "# Iterate through tags one by one\n",
    "# for tag in tags:\n",
    "# print(f\"Querying for tag: {tag}\")\n",
    "for team, players in team_dict.items():\n",
    "    print(f\"Querying for team: {team} with tag: {tags}\")\n",
    "    team_posts = client.app.bsky.feed.search_posts(\n",
    "        params=models.AppBskyFeedSearchPosts.Params(\n",
    "            q=team,\n",
    "            since=datetime.strptime(f\"2024-11-15\", \"%Y-%m-%d\").isoformat() + \".000000Z\",\n",
    "            until=datetime.strptime(f\"2024-11-20\", \"%Y-%m-%d\").isoformat().replace(\"T00:00:00\", '') + \"T23:59:59.999999Z\",\n",
    "            tag=tags \n",
    "        )\n",
    "    )\n",
    "    for post in team_posts.posts:\n",
    "        # Add team posts to CSV data\n",
    "        csv_data.append({\n",
    "            \"team\": team,\n",
    "            \"post\": post.record.text,\n",
    "            \"post_author\": post.author.display_name,\n",
    "            \"post_time\": post.record.created_at,\n",
    "            \"tag\": tags\n",
    "        })\n",
    "    for player in players:\n",
    "        # Collect posts for each player\n",
    "        print(f\"Querying for player: {player} in team {team} with tag: {tag}\")\n",
    "        player_posts = client.app.bsky.feed.search_posts(\n",
    "            params=models.AppBskyFeedSearchPosts.Params(\n",
    "                q=player,\n",
    "                since=datetime.strptime(f\"2024-11-15\", \"%Y-%m-%d\").isoformat() + \".000000Z\",\n",
    "                until=datetime.strptime(f\"2024-11-20\", \"%Y-%m-%d\").isoformat().replace(\"T00:00:00\", '') + \"T23:59:59.999999Z\",\n",
    "                tag=tags \n",
    "            )\n",
    "        )\n",
    "        for post in player_posts.posts:\n",
    "            # Add player posts to the team's posts\n",
    "            csv_data.append({\n",
    "                \"team\": team,\n",
    "                \"post\": post.record.text,\n",
    "                \"post_author\": post.author.display_name,\n",
    "                \"post_time\": post.record.created_at,\n",
    "                \"tag\": tags\n",
    "            })\n",
    "\n",
    "    # Write the CSV\n",
    "    output_file = f'tagged_posts_cs2.csv'\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"team\", \"post\", \"post_author\", \"post_time\", \"tag\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(csv_data)\n",
    "\n",
    "    print(f\"Tagged posts saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "csposts = pd.read_csv('tagged_posts_cs2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team\n",
      "Rebels           84\n",
      "SAW              76\n",
      "Natus Vincere    64\n",
      "GamerLegion      63\n",
      "FaZe Clan        62\n",
      "Cloud9           51\n",
      "Nemiga           41\n",
      "Fnatic           38\n",
      "Betboom          36\n",
      "ECLOT            20\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(csposts['team'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team\n",
      "Betboom          30\n",
      "GamerLegion      27\n",
      "Fnatic           22\n",
      "ECLOT            13\n",
      "Cloud9           12\n",
      "SAW              12\n",
      "Natus Vincere     8\n",
      "FaZe Clan         7\n",
      "Rebels            6\n",
      "Nemiga            5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "csposts['post_time'] = pd.to_datetime(csposts['post_time'], format='mixed')\n",
    "cspostsSorted = csposts.sort_values(by='post_time')\n",
    "\n",
    "BBVGLCutoff = pd.to_datetime('2024-11-20T08:25:00').tz_localize('UTC') \n",
    "\n",
    "BBVGLDF = csposts[csposts['team'].isin(['Betboom', 'GamerLegion'])]\n",
    "BBVGLDF = BBVGLDF[BBVGLDF['post_time'] < BBVGLCutoff]\n",
    "\n",
    "FnVECLCutoff = pd.to_datetime('2024-11-20T00:00:00').tz_localize('UTC') \n",
    "\n",
    "FnVECLDF = csposts[csposts['team'].isin(['Fnatic', 'ECLOT'])]\n",
    "FnVECLDF = FnVECLDF[FnVECLDF['post_time'] < FnVECLCutoff]\n",
    "\n",
    "FzVC9Cutoff = pd.to_datetime('2024-11-19T07:00:00').tz_localize('UTC') \n",
    "\n",
    "FzVC9DF = csposts[csposts['team'].isin(['FaZe Clan', 'Cloud9'])]\n",
    "FzVC9DF = FzVC9DF[FzVC9DF['post_time'] < FzVC9Cutoff]\n",
    "\n",
    "NVVSAWCutoff = pd.to_datetime('2024-11-19T00:20:00').tz_localize('UTC') \n",
    "\n",
    "NVVSAWDF = csposts[csposts['team'].isin(['Natus Vincere', 'SAW'])]\n",
    "NVVSAWDF = NVVSAWDF[NVVSAWDF['post_time'] < NVVSAWCutoff]\n",
    "\n",
    "NGVRebCutoff = pd.to_datetime('2024-11-18T01:05:00').tz_localize('UTC') \n",
    "\n",
    "NGVRebDF = csposts[csposts['team'].isin(['Nemiga', 'Rebels'])]\n",
    "NGVRebDF = NGVRebDF[NGVRebDF['post_time'] < NGVRebCutoff]\n",
    "\n",
    "\n",
    "\n",
    "BBVGLDF['source'] = 'BlueSky'\n",
    "FnVECLDF['source'] = 'BlueSky'\n",
    "FzVC9DF['source'] = 'BlueSky'\n",
    "NVVSAWDF['source'] = 'BlueSky'\n",
    "NGVRebDF['source'] = 'BlueSky'\n",
    "\n",
    "combined_cs_df = pd.concat([BBVGLDF, FnVECLDF, FzVC9DF, NVVSAWDF, NGVRebDF])\n",
    "\n",
    "# combined_cs_df = combined_cs_df.sort_values(by='post_time')\n",
    "\n",
    "combined_cs_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "combined_cs_df.to_csv('cs_timecutoff_posts.csv', index=False)\n",
    "\n",
    "print(combined_cs_df[\"team\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>post_count</th>\n",
       "      <th>positive_posts</th>\n",
       "      <th>negative_posts</th>\n",
       "      <th>neutral_posts</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Betboom</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cloud9</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECLOT</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FaZe Clan</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fnatic</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GamerLegion</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Natus Vincere</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nemiga</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SAW</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rebels</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            team  post_count  positive_posts  negative_posts  neutral_posts  \\\n",
       "0        Betboom          19               5               3             11   \n",
       "1         Cloud9           8               4               0              4   \n",
       "2          ECLOT          12               3               2              7   \n",
       "3      FaZe Clan           7               4               1              2   \n",
       "4         Fnatic          12               4               4              4   \n",
       "5    GamerLegion          20               7               4              8   \n",
       "6  Natus Vincere           5               4               0              1   \n",
       "7         Nemiga           5               1               3              1   \n",
       "8            SAW           1               1               0              0   \n",
       "9         Rebels           0               0               0              0   \n",
       "\n",
       "   performance  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            1  \n",
       "4            1  \n",
       "5            1  \n",
       "6            1  \n",
       "7            1  \n",
       "8            0  \n",
       "9            0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csposts = pd.read_csv('BlueSky_cs_timecutoff_posts.csv')\n",
    "\n",
    "csposts.dropna(inplace=True)\n",
    "\n",
    "annotation_map = {1: 'positive', 2: 'negative', 3: 'neutral'}\n",
    "\n",
    "csposts['Annotations'] = pd.to_numeric(csposts['Annotations'], errors='coerce')\n",
    "\n",
    "# Group by team and calculate required metrics\n",
    "simplified_data = csposts.groupby('team').agg(\n",
    "    post_count=('post', 'count'),\n",
    "    positive_posts=('Annotations', lambda x: (x == 1).sum()),\n",
    "    negative_posts=('Annotations', lambda x: (x == 2).sum()),\n",
    "    neutral_posts=('Annotations', lambda x: (x == 3).sum())\n",
    ").reset_index()\n",
    "\n",
    "rebels_row = {'team': 'Rebels', 'post_count': 0, 'positive_posts': 0, 'negative_posts': 0, 'neutral_posts': 0}\n",
    "\n",
    "simplified_data.loc[len(simplified_data)] = rebels_row\n",
    "\n",
    "\n",
    "performance_dict = {'Betboom': 0, 'GamerLegion': 1, 'Fnatic': 1, 'ECLOT': 0, 'Cloud9': 0, 'SAW': 0, 'Natus Vincere': 1, 'FaZe Clan': 1, 'Rebels': 0, 'Nemiga': 1}\n",
    "\n",
    "simplified_data['performance'] = simplified_data['team'].map(performance_dict)\n",
    "\n",
    "simplified_data.to_csv(\"team_data.csv\")\n",
    "\n",
    "simplified_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\anaconda\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in e:\\anaconda\\lib\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\anaconda\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in e:\\anaconda\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\anaconda\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\anaconda\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\anaconda\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in e:\\anaconda\\lib\\site-packages (from matplotlib) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in e:\\anaconda\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\anaconda\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\anaconda\\lib\\site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: plotly in e:\\anaconda\\lib\\site-packages (5.24.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in e:\\anaconda\\lib\\site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: packaging in e:\\anaconda\\lib\\site-packages (from plotly) (24.1)\n",
      "Requirement already satisfied: selenium in e:\\anaconda\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in e:\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Requirement already satisfied: trio~=0.17 in e:\\anaconda\\lib\\site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in e:\\anaconda\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in e:\\anaconda\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in e:\\anaconda\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in e:\\anaconda\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in e:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in e:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in e:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in e:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in e:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in e:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in e:\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in e:\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in e:\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in e:\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: bs4 in e:\\anaconda\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in e:\\anaconda\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in e:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: praw in e:\\anaconda\\lib\\site-packages (7.7.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in e:\\anaconda\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in e:\\anaconda\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in e:\\anaconda\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in e:\\anaconda\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2024.8.30)\n",
      "Requirement already satisfied: textblob in e:\\anaconda\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in e:\\anaconda\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->textblob) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->textblob) (4.66.4)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Requirement already satisfied: nltk in e:\\anaconda\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in e:\\anaconda\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in e:\\anaconda\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\anaconda\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: networkx in e:\\anaconda\\lib\\site-packages (3.3)\n",
      "Requirement already satisfied: scipy in e:\\anaconda\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in e:\\anaconda\\lib\\site-packages (from scipy) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install plotly\n",
    "!pip install selenium\n",
    "!pip install bs4\n",
    "!pip install praw\n",
    "!pip install textblob\n",
    "!pip install nltk\n",
    "!pip install networkx\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dunca\\AppData\\Local\\Temp\\ipykernel_6620\\4234844595.py:14: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('retina')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"This cell imports necessary Python modules and performs initial configuration\n",
    "\"\"\"\n",
    "\n",
    "# Data manipulation libraries\n",
    "import json\n",
    "import pandas as pd \n",
    "import csv\n",
    "\n",
    "\n",
    "# Visualization and Interaction\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.style.use('ggplot')\n",
    "from IPython.display import set_matplotlib_formats, display, clear_output, HTML\n",
    "set_matplotlib_formats('retina')\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
    "init_notebook_mode(connected=True)\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets import VBox, HBox, Button, HTML, Label\n",
    "\n",
    "\n",
    "# Computation libraries \n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "# Graph analysis\n",
    "# import networkx as nx\n",
    "# import community\n",
    "\n",
    "\n",
    "# System related\n",
    "# import sys\n",
    "# import warnings;\n",
    "# warnings.filterwarnings('ignore')\n",
    "import io\n",
    "import platform\n",
    "from pathlib import Path\n",
    "import os\n",
    "from getpass import getpass\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "# Datetime libraries\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pytz import timezone\n",
    "\n",
    "\n",
    "# NLP dependencies\n",
    "# import spacy\n",
    "# from spacy.tokenizer import Tokenizer\n",
    "# nlp = spacy.load('en')\n",
    "# tokenizer = Tokenizer(nlp.vocab)\n",
    "# from langdetect import detect\n",
    "\n",
    "\n",
    "# Scraping libraries\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Machine learning libraries\n",
    "# from sklearn import datasets\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Logging\n",
    "import logging \n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "# For Reddit\n",
    "import praw\n",
    "from praw.models import MoreComments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell defines global variables and parameters used throughout the playbook\n",
    "\"\"\"\n",
    "\n",
    "# Set this to True if you want to watch Selenium scrape pages\n",
    "# WATCH_SCRAPING = True\n",
    "\n",
    "# Set this to True if you want to use incognito mode\n",
    "# USE_INCOGNITO = True\n",
    "\n",
    "# Number of posts \n",
    "post_limit = 1000\n",
    "\n",
    "# The data is written \n",
    "RAW_DATA_DIRECTORY = Path(\"\")\n",
    "\n",
    "# Setup logging level\n",
    "LOGGING_LEVEL = logging.INFO \n",
    "logging.basicConfig(level=LOGGING_LEVEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell defines functions and classes used throughout the playbook\n",
    "\"\"\"\n",
    "\n",
    "def __init__(self, client_id, client_secret, user_agent, password):\n",
    "    self.client_id = client_id\n",
    "    self.client_secret = client_secret\n",
    "    self.user_agent = user_agent\n",
    "    self.password = password\n",
    "\n",
    "\n",
    "def token(client_id, client_secret, user_agent):\n",
    "    reddit = praw.Reddit(client_id=client_id,\n",
    "                         client_secret=client_secret,\n",
    "                         user_agent=user_agent)\n",
    "    if (reddit != False):\n",
    "        print(\"Successful token\")\n",
    "    else:\n",
    "        print(\"Failed token\")\n",
    "    return reddit\n",
    "\n",
    "def search_subreddit(reddit, search_term, sort_type, time_limit, post_limit, sub_reddit):\n",
    "    \"\"\"\n",
    "    GRAB REDDIT POSTS BY SEARCH TERM\n",
    "    search_term = any boolean search #https://www.reddit.com/dev/api/\n",
    "    sort_type = 'relevance', 'hot', 'top', 'new', 'comments'\n",
    "    time_limit = 'all', 'hour', 'day', 'week', 'month', 'year'\n",
    "    post_limit = 1000 maximum\n",
    "    \"\"\"\n",
    "\n",
    "    posts = []\n",
    "    subreddit = reddit.subreddit(sub_reddit)\n",
    "    for post in subreddit.search(search_term, sort=sort_type, time_filter=time_limit, limit=post_limit):\n",
    "        posts.append([post.subreddit, post.id, post.title, post.selftext, post.author, post.url, post.permalink,\n",
    "                      post.num_comments, post.created, post.score, post.distinguished, post.is_original_content,\n",
    "                      post.upvote_ratio, post.link_flair_text])\n",
    "    posts = pd.DataFrame(posts,\n",
    "                         columns=['subreddit', 'post_id', 'title', 'post_body', 'post_author', 'url', 'post_permalink',\n",
    "                                  'num_comments', 'post_created', 'post_score', 'post_distinguished',\n",
    "                                  'original_content', 'upvote_ratio', 'flair_text'])\n",
    "    posts['post_created'] = pd.to_datetime(posts['post_created'], unit='s')\n",
    "    posts['scrape_time'] = datetime.now()\n",
    "    posts[['subreddit', 'post_id', 'title', 'post_author',\n",
    "           'post_body', 'url', 'post_permalink', 'flair_text']] = posts[['subreddit', 'post_id', 'title', 'post_author',\n",
    "                                                                         'post_body', 'url', 'post_permalink',\n",
    "                                                                         'flair_text']].astype(str)\n",
    "    return posts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System-dependent Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell defines system-dependent configuration such as those different in Linux vs. Windows\n",
    "\"\"\"\n",
    "\n",
    "# Get the system information from the OS\n",
    "PLATFORM_SYSTEM = platform.system()\n",
    "\n",
    "# Darwin is macOS\n",
    "if PLATFORM_SYSTEM == \"Darwin\":\n",
    "    EXECUTABLE_PATH = Path(\"../dependencies/chromedriver\")\n",
    "elif PLATFORM_SYSTEM == \"Windows\":\n",
    "    EXECUTABLE_PATH = Path(\"../dependencies/chromedriver.exe\")\n",
    "else:\n",
    "    logging.critical(\"Chromedriver not found or Chromedriver is outdated...\")\n",
    "    exit()\n",
    "    \n",
    "tz = timezone('US/Eastern')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Reddit Submissions and Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful token\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Zorte In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 11 posts with search term: Zorte In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Magnojez In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 12 posts with search term: Magnojez In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Nafay In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 0 posts with search term: Nafay In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: S1ren In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 11 posts with search term: S1ren In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: KaiRON- In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 1 posts with search term: KaiRON- In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 1 posts with search term: Ax1Le In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 16 posts with search term: Ax1Le In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 1 posts with search term: Boombl4 In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 19 posts with search term: Boombl4 In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 1 posts with search term: HeavyGod In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 19 posts with search term: HeavyGod In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 1 posts with search term: ICY In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 18 posts with search term: ICY In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 1 posts with search term: interz In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 15 posts with search term: interz In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Dytor In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 7 posts with search term: Dytor In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: nbqq In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 8 posts with search term: nbqq In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: FORSYY In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 7 posts with search term: FORSYY In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Blytz In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 7 posts with search term: Blytz In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: kreaz In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 7 posts with search term: kreaz In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 14 posts with search term: rain In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 24 posts with search term: rain In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: broky In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 15 posts with search term: broky In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: karrigan In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 20 posts with search term: karrigan In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 2 posts with search term: ropz In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 17 posts with search term: ropz In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 2 posts with search term: frozen In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 16 posts with search term: frozen In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: KRIMZ In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 15 posts with search term: KRIMZ In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: bodyy In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 12 posts with search term: bodyy In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: matys In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 14 posts with search term: matys In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: blameF In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 18 posts with search term: blameF In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: nawwk In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 12 posts with search term: nawwk In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 1 posts with search term: Fl4mus In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 18 posts with search term: Fl4mus In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Zorte In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 11 posts with search term: Zorte In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Tauson In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 16 posts with search term: Tauson In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Sl3nd In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 17 posts with search term: Sl3nd In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Volt In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 15 posts with search term: Volt In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: b1t In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 14 posts with search term: b1t In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 2 posts with search term: Aleksib In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 13 posts with search term: Aleksib In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 4 posts with search term: jL In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 16 posts with search term: jL In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 248 posts with search term: iM In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 250 posts with search term: iM In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 1 posts with search term: w0nderful In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 10 posts with search term: w0nderful In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Xant3r In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 7 posts with search term: Xant3r In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: 1eer In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 5 posts with search term: 1eer In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Riskyb0b In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 7 posts with search term: Riskyb0b In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: khaN In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 7 posts with search term: khaN In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: zweih In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 7 posts with search term: zweih In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Innocent In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 5 posts with search term: Innocent In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Casey In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 5 posts with search term: Casey In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 1 posts with search term: Olimp In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 5 posts with search term: Olimp In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Flayy In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 5 posts with search term: Flayy In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Kisserek In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 5 posts with search term: Kisserek In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: MUTiRiS In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 7 posts with search term: MUTiRiS In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: rmn In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 2 posts with search term: rmn In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: ewjerkz In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 8 posts with search term: ewjerkz In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 12 posts with search term: story In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 24 posts with search term: story In subreddit:  GlobalOffensive\n",
      "cs2\n",
      "Grabbed 0 posts with search term: Ag1l In subreddit:  cs2\n",
      "GlobalOffensive\n",
      "Grabbed 5 posts with search term: Ag1l In subreddit:  GlobalOffensive\n",
      "Number of posts:  1097\n",
      "Exported posts to CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dunca\\AppData\\Local\\Temp\\ipykernel_6620\\713749511.py:47: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This cell retrieves page posts and comments, for a given page.\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    # Credentials (create client_id, client_secret, user_agent by following https://praw.readthedocs.io/en/latest/getting_started/quick_start.html)\n",
    "    client_id = 'Mo7nM-yhqz1cww'\n",
    "    client_secret = '-4O8dN-Emr5PdkQfy8ifCSVlihE'\n",
    "    user_agent = 'collectPosts'\n",
    "\n",
    "    ''' Designate input parameters for functions\n",
    "    search terms = key terms to search ALL of reddit\n",
    "    subreddits = subreddits to collect\n",
    "    search_sort_type = 'relevance', 'hot', 'top', 'new', 'comments'\n",
    "    sub_sort_type = 'hot', 'top', 'new', 'gilded', 'rising', 'controversial'\n",
    "    time_limit = 'all', 'hour', 'day', 'week', 'month', 'year'\n",
    "    post_limit = 10\n",
    "    '''\n",
    "\n",
    "    sub_sort_type = 'top'  # , 'top', 'new', 'gilded', 'rising', 'controversial'\n",
    "    search_sort_type = 'top'  # , 'hot', 'top', 'new', 'comments', 'relevance'\n",
    "    time_limit = 'month'  # , 'hour', 'day', 'week', 'month', 'year'\n",
    "    \n",
    "    search_terms = ['Zorte', 'Magnojez', 'Nafay', 'S1ren', 'KaiRON-', 'Ax1Le', 'Boombl4', 'HeavyGod', 'ICY', 'interz', 'Dytor', 'nbqq', 'FORSYY', 'Blytz', 'kreaz', 'rain', 'broky', 'karrigan', 'ropz', 'frozen', 'KRIMZ', 'bodyy', 'matys', 'blameF', 'nawwk', 'Fl4mus', 'Zorte', 'Tauson', 'Sl3nd', 'Volt', 'b1t', 'Aleksib', 'jL', 'iM', 'w0nderful', 'Xant3r', '1eer', 'Riskyb0b', 'khaN', 'zweih', 'Innocent', 'Casey', 'Olimp', 'Flayy', 'Kisserek','MUTiRiS', 'rmn', 'ewjerkz', 'story', 'Ag1l']\n",
    "    subreddits = ['cs2', 'GlobalOffensive']\n",
    "\n",
    "    # input_search_terms = input(\"Enter search terms (seperated by spaces): \")\n",
    "    # search_terms = input_search_terms.split()\n",
    "    \n",
    "    # input_subreddits = input(\"Enter subreddits (separated by spaces): \")\n",
    "    # subreddits = input_subreddits.split()\n",
    "    \n",
    "    ''' Collect posts & corresponding comments\n",
    "    '''\n",
    "    # Create client\n",
    "    r = token(client_id, client_secret, user_agent)\n",
    "    list_posts_df = []\n",
    "    try:\n",
    "        for query in search_terms:\n",
    "            for subreddit in subreddits:\n",
    "                print(subreddit)\n",
    "                post_df = search_subreddit(r, query, search_sort_type, time_limit, post_limit, subreddit)\n",
    "                print(\"Grabbed\", len(post_df), \"posts with search term:\", query, \"In subreddit: \", subreddit)\n",
    "                list_posts_df.append(post_df)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    new_posts = pd.concat(list_posts_df)\n",
    "    print(\"Number of posts: \", new_posts.shape[0])\n",
    "\n",
    "    # File output for posts\n",
    "    filename_csv = \"cs_reddit_posts.csv\"\n",
    "    new_posts.to_csv(str(RAW_DATA_DIRECTORY / filename_csv), index=False)\n",
    "    print(\"Exported posts to CSV\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_time(df):\n",
    "    csposts = df\n",
    "    BBVGLCutoff = pd.Timestamp('2024-11-20T08:25:00')\n",
    "\n",
    "    BBVGLDF = csposts[csposts['team'].isin(['Betboom', 'GamerLegion'])]\n",
    "    BBVGLDF = BBVGLDF[BBVGLDF['post_created'] < BBVGLCutoff]\n",
    "\n",
    "    FnVECLCutoff = pd.Timestamp('2024-11-20T00:00:00')\n",
    "\n",
    "    FnVECLDF = csposts[csposts['team'].isin(['Fnatic', 'ECLOT'])]\n",
    "    FnVECLDF = FnVECLDF[FnVECLDF['post_created'] < FnVECLCutoff]\n",
    "\n",
    "    FzVC9Cutoff = pd.Timestamp('2024-11-19T07:00:00')\n",
    "\n",
    "    FzVC9DF = csposts[csposts['team'].isin(['FaZe Clan', 'Cloud9'])]\n",
    "    FzVC9DF = FzVC9DF[FzVC9DF['post_created'] < FzVC9Cutoff]\n",
    "\n",
    "    NVVSAWCutoff = pd.Timestamp('2024-11-19T00:20:00')\n",
    "\n",
    "    NVVSAWDF = csposts[csposts['team'].isin(['Natus Vincere', 'SAW'])]\n",
    "    NVVSAWDF = NVVSAWDF[NVVSAWDF['post_created'] < NVVSAWCutoff]\n",
    "\n",
    "    NGVRebCutoff = pd.Timestamp('2024-11-18T01:05:00')\n",
    "\n",
    "    NGVRebDF = csposts[csposts['team'].isin(['Nemiga', 'Rebels'])]\n",
    "    NGVRebDF = NGVRebDF[NGVRebDF['post_created'] < NGVRebCutoff]\n",
    "\n",
    "    BBVGLDF['source'] = 'reddit'\n",
    "    FnVECLDF['source'] = 'reddit'\n",
    "    FzVC9DF['source'] = 'reddit'\n",
    "    NVVSAWDF['source'] = 'reddit'\n",
    "    NGVRebDF['source'] = 'reddit'\n",
    "\n",
    "    combined_cs_df = pd.concat([BBVGLDF, FnVECLDF, FzVC9DF, NVVSAWDF, NGVRebDF])\n",
    "\n",
    "    # combined_cs_df = combined_cs_df.sort_values(by='post_time')\n",
    "\n",
    "    combined_cs_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return combined_cs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team\n",
      "Natus Vincere    60\n",
      "FaZe Clan        11\n",
      "GamerLegion      10\n",
      "SAW               8\n",
      "Fnatic            7\n",
      "Cloud9            6\n",
      "ECLOT             6\n",
      "Betboom           5\n",
      "Nemiga            3\n",
      "Rebels            3\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dunca\\AppData\\Local\\Temp\\ipykernel_6620\\3898105190.py:52: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('cs_reddit_posts.csv')\n",
    "\n",
    "df['post_created'] = pd.to_datetime(df['post_created'])\n",
    "\n",
    "\n",
    "tourney_start = pd.Timestamp('2024-11-15') #Couple days before like above\n",
    "tourney_end = pd.Timestamp('2024-11-20')\n",
    "\n",
    "df = df[tourney_start <= df['post_created']]\n",
    "df = df[df['post_created'] <= tourney_end]\n",
    "df['source'] = 'Reddit'\n",
    "\n",
    "teamlist = ['Natus Vincere', 'FaZe Clan', 'SAW', 'Fnatic', 'Cloud9', 'Rebels', 'Betboom', 'GamerLegion', 'ECLOT', 'Nemiga']\n",
    "\n",
    "team_players = {\n",
    "    'Betboom': ['Zorte', 'Magnojez', 'Nafay', 'S1ren', 'KaiRON-'],\n",
    "    'Cloud9': ['Ax1Le', 'Boombl4', 'HeavyGod', 'ICY', 'interz'],\n",
    "    'ECLOT': ['Dytor', 'nbqq', 'FORSYY', 'Blytz', 'kreaz'],\n",
    "    'FaZe Clan': ['rain', 'broky', 'karrigan', 'ropz', 'frozen'],\n",
    "    'Fnatic': ['KRIMZ', 'bodyy', 'matys', 'blameF', 'nawwk'],\n",
    "    'GamerLegion': ['Fl4mus', 'Zorte', 'Tauson', 'Sl3nd', 'Volt'],\n",
    "    'Natus Vincere': ['b1t', 'Aleksib', 'jL', 'iM', 'w0nderful'],\n",
    "    'Nemiga': ['Xant3r', '1eer', 'Riskyb0b', 'khaN', 'zweih'],\n",
    "    'Rebels': ['Innocent', 'Casey', 'Olimp', 'Flayy', 'Kisserek'],\n",
    "    'SAW': ['MUTiRiS', 'rmn', 'ewjerkz', 'story', 'Ag1l']\n",
    "}\n",
    "\n",
    "# Compile a regex pattern for both team and player names\n",
    "pattern = '|'.join(teamlist + [player for players in team_players.values() for player in players])\n",
    "\n",
    "# Ensure 'post_body' and 'title' are combined to account for both\n",
    "df['content'] = df['post_body'] + \" \" + df['title']\n",
    "\n",
    "# Filter posts containing any team or player\n",
    "df_filtered = df[df['content'].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "# Function to categorize posts by team and players\n",
    "def categorize_post_to_multiple_teams(row, team_players):\n",
    "    teams_mentioned = []\n",
    "    for team, players in team_players.items():\n",
    "        # Check if the team is mentioned\n",
    "        if team.lower() in row['content'].lower():\n",
    "            teams_mentioned.append(team)\n",
    "        \n",
    "        # Check if any of the players is mentioned\n",
    "        for player in players:\n",
    "            if player.lower() in row['content'].lower() and team not in teams_mentioned:\n",
    "                teams_mentioned.append(team)\n",
    "    return teams_mentioned  # Return a list of teams\n",
    "\n",
    "# Apply categorization to assign posts to all mentioned teams\n",
    "df_filtered['team'] = df_filtered.apply(lambda row: categorize_post_to_multiple_teams(row, team_players), axis=1)\n",
    "\n",
    "# Explode the DataFrame so each row corresponds to one team and one post\n",
    "df_result = df_filtered.explode('team')\n",
    "\n",
    "df_cut = cut_time(df_result)\n",
    "\n",
    "\n",
    "# Rename columns and save the result\n",
    "df_cut = df_cut[['team', 'content']].rename(columns={'teams': 'team', 'content': 'post'})\n",
    "df_cut[\"source\"] = \"reddit\"\n",
    "\n",
    "df_cut.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "df_cut.to_csv('cs_posts_timecutoff_reddit.csv', index=False)\n",
    "\n",
    "print(df_cut[\"team\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>post_count</th>\n",
       "      <th>positive_posts</th>\n",
       "      <th>negative_posts</th>\n",
       "      <th>neutral_posts</th>\n",
       "      <th>performance</th>\n",
       "      <th>time_since_creation_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Betboom</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cloud9</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECLOT</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FaZe Clan</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fnatic</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GamerLegion</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Natus Vincere</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nemiga</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rebels</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SAW</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            team  post_count  positive_posts  negative_posts  neutral_posts  \\\n",
       "0        Betboom          24               5               3             16   \n",
       "1         Cloud9          14               4               0             10   \n",
       "2          ECLOT          18               4               2             12   \n",
       "3      FaZe Clan          11               4               1              6   \n",
       "4         Fnatic          19               5               5              9   \n",
       "5    GamerLegion          30               7               5             17   \n",
       "6  Natus Vincere          21               5               1             15   \n",
       "7         Nemiga           8               1               3              4   \n",
       "8         Rebels           3               0               0              3   \n",
       "9            SAW           6               1               0              5   \n",
       "\n",
       "   performance  time_since_creation_days  \n",
       "0            0                       490  \n",
       "1            0                      3776  \n",
       "2            0                      3133  \n",
       "3            1                      3239  \n",
       "4            1                      7437  \n",
       "5            1                      2075  \n",
       "6            1                      5464  \n",
       "7            1                      2737  \n",
       "8            0                       325  \n",
       "9            0                      1797  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cs_annotated_posts_reddit.csv')\n",
    "\n",
    "# print(df['team'].value_counts())\n",
    "\n",
    "df['sentiment'] = pd.to_numeric(df['sentiment'], errors='coerce')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df = df.drop(df[df['sentiment'] == 4].index)\n",
    "\n",
    "# print(df['team'].value_counts())\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# print(df['team'].value_counts())\n",
    "\n",
    "simplified_data_reddit = df.groupby('team').agg(\n",
    "    post_count=('post', 'count'),\n",
    "    positive_posts=('sentiment', lambda x: (x == 1).sum()),\n",
    "    negative_posts=('sentiment', lambda x: (x == 2).sum()),\n",
    "    neutral_posts=('sentiment', lambda x: (x == 3).sum())\n",
    ").reset_index()\n",
    "\n",
    "performance_dict = {'Betboom': 0, 'GamerLegion': 0, 'Fnatic': 0, 'ECLOT': 0, 'Cloud9': 0, 'SAW': 0, 'Natus Vincere': 0, 'FaZe Clan':0, 'Rebels': 0, 'Nemiga': 0} #Set all to 0 so we dont add a these together\n",
    "simplified_data_reddit['performance'] = simplified_data_reddit['team'].map(performance_dict)\n",
    "\n",
    "simplified_data_reddit\n",
    "\n",
    "df_bluesky_simple = pd.read_csv('team_data.csv')\n",
    "\n",
    "df_bluesky_simple\n",
    "\n",
    "frames = [simplified_data_reddit, df_bluesky_simple]\n",
    "\n",
    "result_df = pd.concat(frames).groupby('team', as_index=False).sum()\n",
    "\n",
    "#Forgot I was going over only singular games not overall performance, left incase I revisit\n",
    "# overall_performance_dict = {'Betboom': 8, 'GamerLegion': 7, 'Fnatic': 6, 'ECLOT': 11, 'Cloud9': 5, 'SAW': 10, 'Natus Vincere': 4, 'FaZe Clan':3, 'Rebels': 16, 'Nemiga': 12} \n",
    "# result_df['overall_performance'] = result_df['team'].map(overall_performance_dict)\n",
    "\n",
    "now = pd.Timestamp.now()\n",
    "\n",
    "team_creation = {'Betboom': (now - pd.Timestamp('2023-07-31')).days, 'GamerLegion': (now - pd.Timestamp('2019-03-29')).days, 'Fnatic': (now - pd.Timestamp('2004-07-23')).days,\\\n",
    "                 'ECLOT': (now - pd.Timestamp('2016-05-05')).days, 'Cloud9': (now - pd.Timestamp('2014-08-01')).days, 'SAW': (now - pd.Timestamp('2020-01-01')).days, \\\n",
    "                 'Natus Vincere': (now - pd.Timestamp('2009-12-17')).days, 'FaZe Clan':(now - pd.Timestamp('2016-01-20')).days, 'Rebels': (now - pd.Timestamp('2024-01-12')).days, \\\n",
    "                 'Nemiga': (now - pd.Timestamp('2017-06-05')).days} \n",
    "result_df['time_since_creation_days'] = result_df['team'].map(team_creation)\n",
    "\n",
    "\n",
    "result_df.to_csv('team_performances_by_annotation.csv')\n",
    "\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
