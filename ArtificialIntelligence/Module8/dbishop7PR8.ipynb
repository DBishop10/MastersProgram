{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "1. Change the name of this file to be your JHED id as in `jsmith299.ipynb`. Because sure you use your JHED ID (it's made out of your name and not your student id which is just letters and numbers).\n",
    "2. Make sure the notebook you submit is cleanly and fully executed. I do not grade unexecuted notebooks.\n",
    "3. Submit your notebook back in Blackboard where you downloaded this file.\n",
    "\n",
    "*Provide the output **exactly** as requested*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "import math\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Any, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "For this assignment you will be implementing and evaluating a Decision Tree using the ID3 Algorithm (**no** pruning or normalized information gain). Use the provided pseudocode. The data is located at (copy link):\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "**Just in case** the UCI repository is down, which happens from time to time, I have included the data and name files on Canvas.\n",
    "\n",
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <strong>Important</strong>\n",
    "    <p>\n",
    "        No Pandas. The only acceptable libraries in this class are those contained in the `environment.yml`. No OOP, either. You can used Dicts, NamedTuples, etc. as your abstract data type (ADT) for the the tree and nodes.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "One of the things we did not talk about in the lectures was how to deal with missing values. There are two aspects of the problem here. What do we do with missing values in the training data? What do we do with missing values when doing classifcation?\n",
    "\n",
    "There are a lot of different ways that we can handle this.\n",
    "A common algorithm is to use something like kNN to impute the missing values.\n",
    "We can use conditional probability as well.\n",
    "There are also clever modifications to the Decision Tree algorithm itself that one can make.\n",
    "\n",
    "We're going to do something simpler, given the size of the data set: remove the observations with missing values (\"?\").\n",
    "\n",
    "You must implement the following functions:\n",
    "\n",
    "`train` takes training_data and returns the Decision Tree as a data structure.\n",
    "\n",
    "```\n",
    "def train(training_data):\n",
    "   # returns the Decision Tree.\n",
    "```\n",
    "\n",
    "`classify` takes a tree produced from the function above and applies it to labeled data (like the test set) or unlabeled data (like some new data).\n",
    "\n",
    "```\n",
    "def classify(tree, observations, labeled=True):\n",
    "    # returns a list of classifications\n",
    "```\n",
    "\n",
    "`evaluate` takes a data set with labels (like the training set or test set) and the classification result and calculates the classification error rate:\n",
    "\n",
    "$$error\\_rate=\\frac{errors}{n}$$\n",
    "\n",
    "Do not use anything else as evaluation metric or the submission will be deemed incomplete, ie, an \"F\". (Hint: accuracy rate is not the error rate!).\n",
    "\n",
    "`cross_validate` takes the data and uses 5x2 fold cross validation (from Module 2!) to `train`, `classify`, and `evaluate`. **Remember to shuffle your data before you create your folds**. I leave the exact signature of `cross_validate` to you but you should write it so that you can use it with *any* `classify` function of the same form (using higher order functions and partial application).\n",
    "\n",
    "Following Module 2's material (course notes), `cross_validate` should print out a table in exactly the same format. What you are looking for here is a consistent evaluation metric cross the folds. Print the error rate to 4 decimal places. **Do not convert to a percentage.**\n",
    "\n",
    "```\n",
    "def pretty_print_tree(tree):\n",
    "    # pretty prints the tree\n",
    "```\n",
    "\n",
    "This should be a text representation of a decision tree trained on the entire data set (no train/test).\n",
    "\n",
    "To summarize...\n",
    "\n",
    "Apply the Decision Tree algorithm to the Mushroom data set using 5x2 cross validation and the error rate as the evaluation metric. When you are done, apply the Decision Tree algorithm to the entire data set and print out the resulting tree.\n",
    "\n",
    "**Note** Because this assignment has a natural recursive implementation, you should consider using `deepcopy` at the appropriate places.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided Functions\n",
    "\n",
    "You do not need to document these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this function to read the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> list[list]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = line.rstrip().split(\",\")\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this function to create 10 folds for 5x2 cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(xs: list, n: int) -> list[list[list]]:\n",
    "    k, m = divmod(len(xs), n)\n",
    "    # be careful of generators...\n",
    "    return list(xs[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your code after this line:\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `entropy` <a id=\"entropy\"></a>\n",
    "\n",
    "**Description:**\n",
    "This function calculates the entropy of a dataset. Entropy is a measure of impurity or disorder within a set. This function is important as it helps determine the optimal splits for the dataset.\n",
    "\n",
    "**Parameters**:\n",
    "- `data` (`list[list[str]]`): where each inner list represents a data point, and the first element of each data point is the class label.\n",
    "\n",
    "**Returns**:\n",
    "- A float representing the entropy of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data:  List[List[str]]):\n",
    "    labels = [datapoint[0] for datapoint in data]\n",
    "    label_counts = Counter(labels)\n",
    "    total_count = len(data)\n",
    "    \n",
    "    ent = 0\n",
    "    for count in label_counts.values():\n",
    "        prob = count / total_count\n",
    "        ent -= prob * math.log2(prob)\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [['A'], ['B'], ['A'], ['B']]\n",
    "assert(entropy(data1) == 1.0) #Equal distribution should be 1\n",
    "\n",
    "data2 = [['A'], ['A'], ['A'], ['A']]\n",
    "assert(entropy(data2) == 0.0) # Single class should be a 0 entropy\n",
    "\n",
    "data3 = [['A'], ['A'], ['B'], ['B'], ['C']]\n",
    "expected_entropy = -(2/5 * math.log2(2/5) + 2/5 * math.log2(2/5) + 1/5 * math.log2(1/5))\n",
    "assert(abs(entropy(data3) - expected_entropy) < 1e-9) #Entropy with 3 classes, did self calculation to compare it to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `information_gain` <a id=\"information_gain\"></a>\n",
    "\n",
    "**Description:**  \n",
    "This function calculates the information gain of splitting the dataset based on a given attribute. Information gain helps measure the reduction in entropy after splitting a dataset and is critical for building decision trees.\n",
    "\n",
    "**Parameters**:  \n",
    "- `data` (`list[list[str]]`): The dataset where each inner list represents a data point.\n",
    "- `attr_index` (`int`): The index of the attribute in the dataset to split on.\n",
    "\n",
    "**Returns**:  \n",
    "- A float representing the information gain for the specified attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(data: List[List[str]], attr_index: int):\n",
    "    total_entropy = entropy(data)\n",
    "    total_count = len(data)\n",
    "    \n",
    "    attr_values = [datapoint[attr_index] for datapoint in data]\n",
    "    value_counts = Counter(attr_values)\n",
    "    \n",
    "    weighted_entropy = 0\n",
    "    for value, count in value_counts.items():\n",
    "        subset = [datapoint for datapoint in data if datapoint[attr_index] == value]\n",
    "        prob = count / total_count\n",
    "        weighted_entropy += prob * entropy(subset)\n",
    "    \n",
    "    return total_entropy - weighted_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [['A', 'x'], ['A', 'x'], ['B', 'y'], ['B', 'y']]\n",
    "assert(abs(information_gain(data1, 1)) == 1)  # Perfect split, information gain should be 1.0\n",
    "\n",
    "data2 = [['A', 'x'], ['A', 'y'], ['A', 'x'], ['A', 'y']]\n",
    "assert(abs(information_gain(data2, 1)) == 0)  # No class change, information gain should be 0\n",
    "\n",
    "data3 = [['A', 'x'], ['A', 'x'], ['B', 'y'], ['C', 'y']]\n",
    "expected_gain = entropy(data3) - (2/4 * entropy([['A', 'x'], ['A', 'x']]) + 2/4 * entropy([['B', 'y'], ['C', 'y']]))\n",
    "assert(abs(information_gain(data3, 1) - expected_gain) == 0)  # Imperfect split, manually calculated expected gain to check it is returning the correct gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `majority_class` <a id=\"majority_class\"></a>\n",
    "\n",
    "**Description:**  \n",
    "This function determines the most common class (label) in the dataset. It is useful in decision tree algorithms to assign a class when no further splitting is possible or necessary (i.e., when reaching a leaf node).\n",
    "\n",
    "**Parameters**:  \n",
    "- `data` (`list[list[str]]`): The dataset where each inner list represents a data point, and the first element of each data point is the class label.\n",
    "\n",
    "**Returns**:  \n",
    "- The most frequent class label (a string or integer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class(data: List[List[str]]):\n",
    "    labels = [datapoint[0] for datapoint in data]\n",
    "    return Counter(labels).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [['A'], ['B'], ['A'], ['B'], ['A']]\n",
    "assert(majority_class(data1) == 'A')  # 'A' appears most frequently\n",
    "\n",
    "data2 = [['B'], ['B'], ['B']]\n",
    "assert(majority_class(data2) == 'B')  # Only one class, 'B'\n",
    "\n",
    "data3 = [['A'], ['A'], ['A'], ['B'], ['C'], ['A']]\n",
    "assert(majority_class(data3) == 'A')  # 'A' is the majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `train` <a id=\"train\"></a>\n",
    "\n",
    "**Description:**  \n",
    "This function recursively builds a decision tree using the ID3 algorithm. It selects the attribute that provides the highest information gain at each step and splits the dataset based on that attribute until it reaches a base case. The base cases occur when all examples have the same class or when there are no attributes left.\n",
    "\n",
    "**Parameters**:  \n",
    "- `training_data` (`list[list[str]]`): A list of data points, where each data point is a list that contains the class label as the first element, followed by attribute values.\n",
    "\n",
    "**Returns**:  \n",
    "- A decision tree as a nested dictionary, where internal nodes are attribute indices and leaf nodes are class labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data: List[List[str]]):\n",
    "    attributes = list(range(1, len(training_data[0])))\n",
    "    \n",
    "    labels = [datapoint[0] for datapoint in training_data]\n",
    "    if labels.count(labels[0]) == len(labels):\n",
    "        return labels[0]\n",
    "    \n",
    "    if not attributes:\n",
    "        return majority_class(training_data)\n",
    "    \n",
    "    gains = [information_gain(training_data, attr_index) for attr_index in attributes]\n",
    "    best_attr = attributes[gains.index(max(gains))]\n",
    "    \n",
    "    tree = {best_attr: {}}\n",
    "    feature_values = set([datapoint[best_attr] for datapoint in training_data])\n",
    "    \n",
    "    for value in feature_values:\n",
    "        subset = [datapoint for datapoint in training_data if datapoint[best_attr] == value]\n",
    "        tree[best_attr][value] = train(subset)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [['A', 'x'], ['B', 'y'], ['A', 'x'], ['B', 'y']]\n",
    "tree1 = train(data1)\n",
    "assert(isinstance(tree1, dict))  # Tree should be a dictionary\n",
    "\n",
    "data2 = [['A', 'x'], ['A', 'y'], ['A', 'z']]\n",
    "tree2 = train(data2)\n",
    "assert(tree2 == 'A')  # All labels are A, so the tree should return just A\n",
    "\n",
    "data3 = [['A', 'x', 'y'], ['B', 'x', 'n'], ['A', 'z', 'y'], ['B', 'z', 'n']]\n",
    "tree3 = train(data3)\n",
    "assert(tree3[2] != None) # Split is required so there should be something for 2, if not it didnt split right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `classify` <a id=\"classify\"></a>\n",
    "\n",
    "**Description:**  \n",
    "This function takes a decision tree and a list of observations and returns a list of predicted class labels for each observation. The tree is traversed based on the attribute values in the observations. If the `labeled` parameter is set to `True`, the first element of each observation (assumed to be the actual label) is skipped during classification. This is integral to the decision tree process as it is what allows us to predict new values (labeled set to False).\n",
    "\n",
    "**Parameters**:  \n",
    "- `tree` (`dict`): The decision tree, represented as a nested dictionary where internal nodes are attribute indices and leaf nodes are class labels.\n",
    "- `observations` (`list[list]`): A list of observations to classify, where each observation is a list of attribute values.\n",
    "- `labeled` (`bool`): Indicates whether the first element of each observation is the true class label. If `True`, it skips the first element during classification. Defaults to `True`.\n",
    "\n",
    "**Returns**:  \n",
    "- A list of predicted class labels for each observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, observations, labeled=True):\n",
    "    results = []\n",
    "    \n",
    "    for observation in observations:\n",
    "        if labeled:\n",
    "            observation = observation[1:]\n",
    "        \n",
    "        current_tree = tree\n",
    "        \n",
    "        while isinstance(current_tree, dict):\n",
    "            for attr, branches in current_tree.items():\n",
    "                value = observation[attr - 1]\n",
    "                if value in branches:\n",
    "                    current_tree = branches[value]\n",
    "                else:\n",
    "                    current_tree = None  \n",
    "        \n",
    "        results.append(current_tree)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = {1: {'x': 'A', 'y': 'B'}}\n",
    "observations1 = [['A', 'x'], ['B', 'y']]\n",
    "assert(classify(tree1, observations1) == ['A', 'B'])  # Should match tree labels 'A' and 'B'\n",
    "\n",
    "observations2 = [['x'], ['y']]\n",
    "assert(classify(tree1, observations2, labeled=False) == ['A', 'B'])  # Should classify correctly without labels\n",
    "\n",
    "tree2 = {1: {'x': 'A'}}\n",
    "observations3 = [['A', 'z']]  # 'z' is not in the tree\n",
    "assert(classify(tree2, observations3) == [None])  # Should return None for missing branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `evaluate` <a id=\"evaluate\"></a>\n",
    "\n",
    "**Description:**  \n",
    "This function calculates the error rate by comparing actual class labels from the dataset with the predicted labels. It counts the number of incorrect predictions and returns the error rate, which is the proportion of wrong predictions. Necessary to test how well our decision tree is performing\n",
    "\n",
    "**Parameters**:  \n",
    "- `data_set` (`list[list]`): The dataset where each inner list represents a data point, and the first element is the actual class label.\n",
    "- `predictions` (`list[str]`): A list of predicted class labels corresponding to the observations in the dataset.\n",
    "\n",
    "**Returns**:  \n",
    "- A float representing the error rate, calculated as the proportion of incorrect predictions out of the total number of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_set: List[List[str]], predictions: List[str]) -> float:\n",
    "    errors = 0\n",
    "    total = len(data_set)\n",
    "    \n",
    "    for actual, predicted in zip(data_set, predictions):\n",
    "        if actual[0] != predicted: \n",
    "            errors += 1\n",
    "            \n",
    "    return errors / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [['A', 'x'], ['B', 'y'], ['C', 'z']]\n",
    "predictions1 = ['A', 'B', 'C']\n",
    "assert(evaluate(data1, predictions1) == 0.0)  # No errors, error rate should be 0%\n",
    "\n",
    "data2 = [['A', 'x'], ['B', 'y'], ['C', 'z']]\n",
    "predictions2 = ['B', 'C', 'A']\n",
    "assert(evaluate(data2, predictions2) == 1.0)  # All wrong, error rate should be 100%\n",
    "\n",
    "data3 = [['A', 'x'], ['B', 'y'], ['C', 'z'], ['D', 'w']]\n",
    "predictions3 = ['A', 'B', 'C', 'X']\n",
    "assert(evaluate(data3, predictions3) == 0.25)  # One wrong, error rate should be 25%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pretty_print_tree` <a id=\"pretty_print_tree\"></a>\n",
    "\n",
    "**Description:**  \n",
    "This function recursively prints a decision tree in a human readable format. Each decision node is represented by an attribute and its corresponding branches, and each leaf node is represented by the class label.\n",
    "\n",
    "**Parameters**:  \n",
    "- `tree` (`dict`): The decision tree, represented as a nested dictionary where internal nodes are attribute indices and leaf nodes are class labels.\n",
    "- `depth` (`int`): The current depth of the tree. Used internally to manage indentation levels during the recursive printing. Defaults to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_tree(tree, depth=0):\n",
    "        if isinstance(tree, dict):\n",
    "            for attr, branches in tree.items():\n",
    "                for value, branch in branches.items():\n",
    "                    print(f\"{'    ' * depth} |-- {attr} == {value}\")\n",
    "                    pretty_print_tree(branch, depth + 1)\n",
    "        else:\n",
    "            print(f\"{'    ' * depth} |-- {tree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |-- 1 == x\n",
      "     |-- A\n",
      " |-- 1 == y\n",
      "     |-- B\n",
      "\n",
      "\n",
      " |-- 1 == x\n",
      "     |-- 2 == y\n",
      "         |-- A\n",
      "     |-- 2 == z\n",
      "         |-- B\n",
      " |-- 1 == y\n",
      "     |-- C\n",
      "\n",
      "\n",
      " |-- A\n"
     ]
    }
   ],
   "source": [
    "# Don't really know how to test this with asserts so I will instead just print out a few trees and check they look right\n",
    "\n",
    "tree1 = {1: {'x': 'A', 'y': 'B'}} #Simple Tree\n",
    "pretty_print_tree(tree1)\n",
    "\n",
    "print(\"\\n\")\n",
    "tree2 = {1: {'x': {2: {'y': 'A', 'z': 'B'}}, 'y': 'C'}} #Nested Tree\n",
    "pretty_print_tree(tree2)\n",
    "\n",
    "print(\"\\n\")\n",
    "tree3 = 'A' # Just a single leaf node\n",
    "pretty_print_tree(tree3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `cross_validate` <a id=\"cross_validate\"></a>\n",
    "\n",
    "**Description:**  \n",
    "This function performs k-fold cross-validation on a decision tree. The data is split into `k` folds, and for each iteration, one fold is used as the test set, while the other folds are used for training. The function is important as it trains a decision tree on the training data and then evaluates its accuracy on the test fold multiple times to get a better reading of how the decision tree is performing.\n",
    "\n",
    "**Parameters**:  \n",
    "- `data` (`list[list]`): The dataset, where each inner list represents a data point and the first element of each data point is the class label.\n",
    "- `k` (`int`): The number of folds to split the data into. Defaults to 5.\n",
    "\n",
    "**Returns**:  \n",
    "- A float representing the average accuracy across all folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(data: List[List[str]], k: int = 5) -> float:\n",
    "    folds = create_folds(data, k)\n",
    "    \n",
    "    error_rates = []\n",
    "\n",
    "    for i in range(k):\n",
    "        test_fold = folds[i]\n",
    "        train_folds = [fold for j, fold in enumerate(folds) if j != i]\n",
    "        train_data = [item for sublist in train_folds for item in sublist]  \n",
    "        \n",
    "        decision_tree = train(train_data)\n",
    "        \n",
    "        observations = [datapoint[1:] for datapoint in test_fold]\n",
    "        \n",
    "        predictions = classify(decision_tree, observations, labeled=False)\n",
    "        \n",
    "        error_rate = evaluate(test_fold, predictions) * 100\n",
    "        error_rates.append(error_rate)\n",
    "        print(f\"Fold {i+1} error rate: {error_rate:.2f}%\")\n",
    "    \n",
    "    average_accuracy = sum(error_rates) / k\n",
    "    return average_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 error rate: 0.00%\n",
      "Fold 2 error rate: 0.00%\n",
      "Fold 1 error rate: 100.00%\n",
      "Fold 2 error rate: 100.00%\n",
      "Fold 1 error rate: 50.00%\n",
      "Fold 2 error rate: 100.00%\n"
     ]
    }
   ],
   "source": [
    "data1 = [['A', 'x'], ['B', 'y'], ['A', 'x'], ['B', 'y']]\n",
    "assert(cross_validate(data1, k=2) == 0)  # Should be 100% accurate as all A will be x and all B will be y\n",
    "\n",
    "data2 = [['A', 'x'], ['B', 'y'], ['A', 'y'], ['B', 'x']]\n",
    "assert(cross_validate(data2, k=2) == 100)  # Tree can't accurately train on this data as A and B could be x and y so it should retun 0\n",
    "\n",
    "data3 = [['A', 'x'], ['B', 'y'], ['A', 'y']]\n",
    "assert(cross_validate(data3, k=2) == 75)  # Tree should be accurate about 25% of the time (correct 50% for one fold and 0% for the other)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 error rate: 0.25%\n",
      "Fold 2 error rate: 0.00%\n",
      "Fold 3 error rate: 0.00%\n",
      "Fold 4 error rate: 0.00%\n",
      "Fold 5 error rate: 0.00%\n",
      "Average error rate across 5 folds: 0.05%\n",
      " |-- 5 == f\n",
      "     |-- p\n",
      " |-- 5 == y\n",
      "     |-- p\n",
      " |-- 5 == p\n",
      "     |-- p\n",
      " |-- 5 == s\n",
      "     |-- p\n",
      " |-- 5 == m\n",
      "     |-- p\n",
      " |-- 5 == l\n",
      "     |-- e\n",
      " |-- 5 == c\n",
      "     |-- p\n",
      " |-- 5 == a\n",
      "     |-- e\n",
      " |-- 5 == n\n",
      "     |-- 20 == o\n",
      "         |-- e\n",
      "     |-- 20 == k\n",
      "         |-- e\n",
      "     |-- 20 == h\n",
      "         |-- e\n",
      "     |-- 20 == y\n",
      "         |-- e\n",
      "     |-- 20 == n\n",
      "         |-- e\n",
      "     |-- 20 == b\n",
      "         |-- e\n",
      "     |-- 20 == w\n",
      "         |-- 22 == d\n",
      "             |-- 8 == n\n",
      "                 |-- p\n",
      "             |-- 8 == b\n",
      "                 |-- e\n",
      "         |-- 22 == p\n",
      "             |-- e\n",
      "         |-- 22 == l\n",
      "             |-- 3 == n\n",
      "                 |-- e\n",
      "             |-- 3 == w\n",
      "                 |-- p\n",
      "             |-- 3 == c\n",
      "                 |-- e\n",
      "             |-- 3 == y\n",
      "                 |-- p\n",
      "         |-- 22 == g\n",
      "             |-- e\n",
      "         |-- 22 == w\n",
      "             |-- e\n",
      "     |-- 20 == r\n",
      "         |-- p\n"
     ]
    }
   ],
   "source": [
    "# Load the data \n",
    "data = parse_data('data/agaricus-lepiota.data')\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "average_accuracy = cross_validate(data, k=5)\n",
    "print(f\"Average error rate across 5 folds: {average_accuracy:.2f}%\")\n",
    "\n",
    "# Train the decision tree model on all data\n",
    "decision_tree = train(data)\n",
    "\n",
    "# Pretty print the resulting decision tree\n",
    "pretty_print_tree(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Did you provide output exactly as requested?\n",
    "2. Did you re-execute the entire notebook? (\"Restart Kernel and Rull All Cells...\")\n",
    "3. If you did not complete the assignment or had difficulty please explain what gave you the most difficulty in the Markdown cell below.\n",
    "4. Did you change the name of the file to `jhed_id.ipynb`?\n",
    "\n",
    "Do not submit any other files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en605645)",
   "language": "python",
   "name": "en605645"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
